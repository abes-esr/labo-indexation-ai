{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données textuelles (titres et/ou résumés)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook explore les données textuelles des résumés et titres de notices bibliographiques afin de voir si des patterns se dégagent rapidement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "# Import librairies\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from utils_text_processing import *\n",
    "from utils_visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres graphiques\n",
    "%matplotlib inline\n",
    "rc = {\n",
    "    'font.size': 14,\n",
    "    'font.family': 'Arial',\n",
    "    'axes.labelsize': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'figure.max_open_warning': 30}\n",
    "\n",
    "sns.set(font='Arial', rc=rc)\n",
    "sns.set_style(\n",
    "    \"whitegrid\", {\n",
    "        'axes.edgecolor': 'k',\n",
    "        'axes.linewidth': 1,\n",
    "        'axes.grid': True,\n",
    "        'xtick.major.width': 1,\n",
    "        'ytick.major.width': 1\n",
    "        })\n",
    "sns.set_context(\n",
    "    \"notebook\",\n",
    "    font_scale=1.1,\n",
    "    rc={\"lines.linewidth\": 1.5})\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autorisation pour la visualisation par pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"\\\\data\"\n",
    "output_path = path + \"\\\\outputs\"\n",
    "fig_path = path + \"\\\\figs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "working_data_filename = \"working_data_sans_dewey.pkl\"\n",
    "analyse_dewey = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le Fichier de données contient 154508 lignes et  9 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_pickle(os.path.join(data_path, working_data_filename))\n",
    "print(f\"le Fichier de données contient {df.shape[0]} lignes et  {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPN</th>\n",
       "      <th>TITRE</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>RAMEAU</th>\n",
       "      <th>DEWEY</th>\n",
       "      <th>DESCR</th>\n",
       "      <th>presence_chaine_indexation</th>\n",
       "      <th>rameau_chaines_index</th>\n",
       "      <th>rameau_concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000002364</td>\n",
       "      <td>La culture pour vivre</td>\n",
       "      <td>Mort de la culture populaire en France. Mutati...</td>\n",
       "      <td>Culture populaire;Diffusion de la culture;Poli...</td>\n",
       "      <td>840</td>\n",
       "      <td>La culture pour vivre Mort de la culture popul...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Culture populaire, Diffusion de la culture, P...</td>\n",
       "      <td>[Culture populaire, Diffusion de la culture, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000014877</td>\n",
       "      <td>La nuit, le jour : essai psychanalytique sur l...</td>\n",
       "      <td>Discontinuité, latence, rétablissement d’une c...</td>\n",
       "      <td>Complexe de castration;Psychanalyse;Rêves</td>\n",
       "      <td>154.63</td>\n",
       "      <td>La nuit, le jour : essai psychanalytique sur l...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Complexe de castration, Psychanalyse, Rêves]</td>\n",
       "      <td>[Complexe de castration, Psychanalyse, Rêves]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000021857</td>\n",
       "      <td>Ruptures, cultures</td>\n",
       "      <td>Il faut imaginer Robinson sur son île, au mome...</td>\n",
       "      <td>Culture</td>\n",
       "      <td>840</td>\n",
       "      <td>Ruptures, cultures Il faut imaginer Robinson s...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Culture]</td>\n",
       "      <td>[Culture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002564X</td>\n",
       "      <td>La révolution structurale</td>\n",
       "      <td>Mutations ou crises, les brusques accès de fiè...</td>\n",
       "      <td>Structuralisme</td>\n",
       "      <td>100</td>\n",
       "      <td>La révolution structurale Mutations ou crises,...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Structuralisme]</td>\n",
       "      <td>[Structuralisme]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026352</td>\n",
       "      <td>La Destruction du temple</td>\n",
       "      <td>Oswald tire sur Kennedy. Jusque-là, c'est bon,...</td>\n",
       "      <td>Science-fiction américaine -- Traductions fran...</td>\n",
       "      <td>830</td>\n",
       "      <td>La Destruction du temple Oswald tire sur Kenne...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Science-fiction américaine -- Traductions fra...</td>\n",
       "      <td>[Science-fiction américaine, Traductions franç...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PPN                                              TITRE  \\\n",
       "0  000002364                              La culture pour vivre   \n",
       "1  000014877  La nuit, le jour : essai psychanalytique sur l...   \n",
       "2  000021857                                 Ruptures, cultures   \n",
       "3  00002564X                          La révolution structurale   \n",
       "4  000026352                           La Destruction du temple   \n",
       "\n",
       "                                              RESUME  \\\n",
       "0  Mort de la culture populaire en France. Mutati...   \n",
       "1  Discontinuité, latence, rétablissement d’une c...   \n",
       "2  Il faut imaginer Robinson sur son île, au mome...   \n",
       "3  Mutations ou crises, les brusques accès de fiè...   \n",
       "4  Oswald tire sur Kennedy. Jusque-là, c'est bon,...   \n",
       "\n",
       "                                              RAMEAU   DEWEY  \\\n",
       "0  Culture populaire;Diffusion de la culture;Poli...     840   \n",
       "1          Complexe de castration;Psychanalyse;Rêves  154.63   \n",
       "2                                            Culture     840   \n",
       "3                                     Structuralisme     100   \n",
       "4  Science-fiction américaine -- Traductions fran...     830   \n",
       "\n",
       "                                               DESCR  \\\n",
       "0  La culture pour vivre Mort de la culture popul...   \n",
       "1  La nuit, le jour : essai psychanalytique sur l...   \n",
       "2  Ruptures, cultures Il faut imaginer Robinson s...   \n",
       "3  La révolution structurale Mutations ou crises,...   \n",
       "4  La Destruction du temple Oswald tire sur Kenne...   \n",
       "\n",
       "   presence_chaine_indexation  \\\n",
       "0                       False   \n",
       "1                       False   \n",
       "2                       False   \n",
       "3                       False   \n",
       "4                        True   \n",
       "\n",
       "                                rameau_chaines_index  \\\n",
       "0  [Culture populaire, Diffusion de la culture, P...   \n",
       "1      [Complexe de castration, Psychanalyse, Rêves]   \n",
       "2                                          [Culture]   \n",
       "3                                   [Structuralisme]   \n",
       "4  [Science-fiction américaine -- Traductions fra...   \n",
       "\n",
       "                                     rameau_concepts  \n",
       "0  [Culture populaire, Diffusion de la culture, P...  \n",
       "1      [Complexe de castration, Psychanalyse, Rêves]  \n",
       "2                                          [Culture]  \n",
       "3                                   [Structuralisme]  \n",
       "4  [Science-fiction américaine, Traductions franç...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualisation\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sa',\n",
       " 'c',\n",
       " 'mais',\n",
       " 'même',\n",
       " 'fussiez',\n",
       " 'eût',\n",
       " 'les',\n",
       " 'l',\n",
       " 'du',\n",
       " 's',\n",
       " 'furent',\n",
       " 'tes',\n",
       " 'que',\n",
       " 'serait',\n",
       " 'nos',\n",
       " 'je',\n",
       " 'eûtes',\n",
       " 'fusse',\n",
       " 'ce',\n",
       " 'et',\n",
       " 'aurons',\n",
       " 'ils',\n",
       " 'ces',\n",
       " 'est',\n",
       " 'serez',\n",
       " 'notre',\n",
       " 'suis',\n",
       " 'ayant',\n",
       " 'aient',\n",
       " 'lui',\n",
       " 'me',\n",
       " 'tu',\n",
       " 'm',\n",
       " 'j',\n",
       " 'fussent',\n",
       " 'ayants',\n",
       " 'soit',\n",
       " 'sois',\n",
       " 'un',\n",
       " 'votre',\n",
       " 'eussiez',\n",
       " 'étaient',\n",
       " 'étante',\n",
       " 'aura',\n",
       " 'ait',\n",
       " 'mon',\n",
       " 'auriez',\n",
       " 'ne',\n",
       " 'pour',\n",
       " 'serions',\n",
       " 'aie',\n",
       " 'fûmes',\n",
       " 'étiez',\n",
       " 'sur',\n",
       " 'avez',\n",
       " 'aurez',\n",
       " 'soient',\n",
       " 'ont',\n",
       " 'eusse',\n",
       " 'n',\n",
       " 'au',\n",
       " 'aurais',\n",
       " 'étantes',\n",
       " 'leur',\n",
       " 'fusses',\n",
       " 'étants',\n",
       " 'eux',\n",
       " 'ma',\n",
       " 'mes',\n",
       " 'fut',\n",
       " 'qu',\n",
       " 'auraient',\n",
       " 'se',\n",
       " 'seriez',\n",
       " 'eurent',\n",
       " 'il',\n",
       " 'eue',\n",
       " 'ses',\n",
       " 'qui',\n",
       " 'êtes',\n",
       " 'avons',\n",
       " 'avait',\n",
       " 'la',\n",
       " 'pas',\n",
       " 'ayantes',\n",
       " 'ta',\n",
       " 't',\n",
       " 'étées',\n",
       " 'te',\n",
       " 'soyons',\n",
       " 'as',\n",
       " 'soyez',\n",
       " 'vous',\n",
       " 'le',\n",
       " 'en',\n",
       " 'étant',\n",
       " 'fus',\n",
       " 'ayons',\n",
       " 'moi',\n",
       " 'avais',\n",
       " 'elle',\n",
       " 'sont',\n",
       " 'auras',\n",
       " 'd',\n",
       " 'auront',\n",
       " 'ou',\n",
       " 'fût',\n",
       " 'eues',\n",
       " 'étions',\n",
       " 'ayez',\n",
       " 'aurai',\n",
       " 'eusses',\n",
       " 'une',\n",
       " 'serais',\n",
       " 'sera',\n",
       " 'sommes',\n",
       " 'nous',\n",
       " 'été',\n",
       " 'fûtes',\n",
       " 'eussions',\n",
       " 'dans',\n",
       " 'eus',\n",
       " 'ayante',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'vos',\n",
       " 'son',\n",
       " 'ton',\n",
       " 'seraient',\n",
       " 'on',\n",
       " 'avaient',\n",
       " 'eûmes',\n",
       " 'étais',\n",
       " 'de',\n",
       " 'seras',\n",
       " 'était',\n",
       " 'eu',\n",
       " 'par',\n",
       " 'es',\n",
       " 'aux',\n",
       " 'étée',\n",
       " 'eut',\n",
       " 'fussions',\n",
       " 'ai',\n",
       " 'aurions',\n",
       " 'aurait',\n",
       " 'des',\n",
       " 'y',\n",
       " 'seront',\n",
       " 'serai',\n",
       " 'étés',\n",
       " 'eussent',\n",
       " 'à',\n",
       " 'avec',\n",
       " 'serons',\n",
       " 'aies',\n",
       " 'toi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List des stopwords\n",
    "list(set(stopwords.words(\"french\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le voyage en Russie : anthologie des voyageurs français aux XVIIIe et XIXe siècles\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "idx = 698\n",
    "text = df.loc[idx, 'TITRE']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sans lemmatization : Le voyage en Russie : anthologie des voyageurs français aux XVIIIe et XIXe siècles\n",
      "Après lemmatization : le voyage en Russie : anthologie de voyageur français à xviii et xix siècle\n"
     ]
    }
   ],
   "source": [
    "# Exemple lemmatization\n",
    "doc = nlp(text)\n",
    "print(\"Sans lemmatization :\", doc)\n",
    "\n",
    "empty_list = []\n",
    "for token in doc:\n",
    "    empty_list.append(token.lemma_)\n",
    "\n",
    "final_string = ' '.join(map(str,empty_list))\n",
    "print(\"Après lemmatization :\",final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = PreprocessData(\n",
    "    df = df,\n",
    "    input_col=\"TITRE\",\n",
    "    output_col=\"TITRE_processed\",\n",
    "    add_words = [],\n",
    "    numeric = False,\n",
    "    stopw = True,\n",
    "    stem = True,\n",
    "    lem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPN</th>\n",
       "      <th>TITRE</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>RAMEAU</th>\n",
       "      <th>DEWEY</th>\n",
       "      <th>DESCR</th>\n",
       "      <th>presence_chaine_indexation</th>\n",
       "      <th>rameau_chaines_index</th>\n",
       "      <th>rameau_concepts</th>\n",
       "      <th>TITRE_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000002364</td>\n",
       "      <td>La culture pour vivre</td>\n",
       "      <td>Mort de la culture populaire en France. Mutati...</td>\n",
       "      <td>Culture populaire;Diffusion de la culture;Poli...</td>\n",
       "      <td>840</td>\n",
       "      <td>La culture pour vivre Mort de la culture popul...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Culture populaire, Diffusion de la culture, P...</td>\n",
       "      <td>[Culture populaire, Diffusion de la culture, P...</td>\n",
       "      <td>[cultur, vivr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000014877</td>\n",
       "      <td>La nuit, le jour : essai psychanalytique sur l...</td>\n",
       "      <td>Discontinuité, latence, rétablissement d’une c...</td>\n",
       "      <td>Complexe de castration;Psychanalyse;Rêves</td>\n",
       "      <td>154.63</td>\n",
       "      <td>La nuit, le jour : essai psychanalytique sur l...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Complexe de castration, Psychanalyse, Rêves]</td>\n",
       "      <td>[Complexe de castration, Psychanalyse, Rêves]</td>\n",
       "      <td>[nuit, jour, essai, psychanalyt, fonction, men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000021857</td>\n",
       "      <td>Ruptures, cultures</td>\n",
       "      <td>Il faut imaginer Robinson sur son île, au mome...</td>\n",
       "      <td>Culture</td>\n",
       "      <td>840</td>\n",
       "      <td>Ruptures, cultures Il faut imaginer Robinson s...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Culture]</td>\n",
       "      <td>[Culture]</td>\n",
       "      <td>[ruptur, cultur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002564X</td>\n",
       "      <td>La révolution structurale</td>\n",
       "      <td>Mutations ou crises, les brusques accès de fiè...</td>\n",
       "      <td>Structuralisme</td>\n",
       "      <td>100</td>\n",
       "      <td>La révolution structurale Mutations ou crises,...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Structuralisme]</td>\n",
       "      <td>[Structuralisme]</td>\n",
       "      <td>[révolu, structural]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026352</td>\n",
       "      <td>La Destruction du temple</td>\n",
       "      <td>Oswald tire sur Kennedy. Jusque-là, c'est bon,...</td>\n",
       "      <td>Science-fiction américaine -- Traductions fran...</td>\n",
       "      <td>830</td>\n",
       "      <td>La Destruction du temple Oswald tire sur Kenne...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Science-fiction américaine -- Traductions fra...</td>\n",
       "      <td>[Science-fiction américaine, Traductions franç...</td>\n",
       "      <td>[destruct, templ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169658</th>\n",
       "      <td>26899885X</td>\n",
       "      <td>Blablabla : en finir avec le bavardage climatique</td>\n",
       "      <td>Dans le brouhaha de nos conversations et de l'...</td>\n",
       "      <td>Réchauffement de la Terre;Écologie</td>\n",
       "      <td></td>\n",
       "      <td>Blablabla : en finir avec le bavardage climati...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Réchauffement de la Terre, Écologie]</td>\n",
       "      <td>[Réchauffement de la Terre, Écologie]</td>\n",
       "      <td>[blablabl, fin, bavardag, climat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169659</th>\n",
       "      <td>268998884</td>\n",
       "      <td>Politique de transition écologique : Démocrati...</td>\n",
       "      <td>La transition écologique est devenue une préoc...</td>\n",
       "      <td>Aménagement du territoire;Marchés publics;Tran...</td>\n",
       "      <td></td>\n",
       "      <td>Politique de transition écologique : Démocrati...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Aménagement du territoire, Marchés publics, T...</td>\n",
       "      <td>[Aménagement du territoire, Marchés publics, T...</td>\n",
       "      <td>[polit, transit, écolog, démocrat, droit, financ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169660</th>\n",
       "      <td>268999066</td>\n",
       "      <td>Abécédaire : mots et rites d'ailleurs</td>\n",
       "      <td>Je dédie cet abécédaire des concepts des cultu...</td>\n",
       "      <td>Ethnopsychiatrie;Psychanalyse et ésotérisme;Ri...</td>\n",
       "      <td></td>\n",
       "      <td>Abécédaire : mots et rites d'ailleurs Je dédie...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Ethnopsychiatrie, Psychanalyse et ésotérisme,...</td>\n",
       "      <td>[Ethnopsychiatrie, Psychanalyse et ésotérisme,...</td>\n",
       "      <td>[abécédair, mot, rit, d'ailleur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169661</th>\n",
       "      <td>268999503</td>\n",
       "      <td>Consommez moins, consommez mieux</td>\n",
       "      <td>Un cahier pratique et ludique à remplir soi-mê...</td>\n",
       "      <td>Biens de consommation durables;Consommation --...</td>\n",
       "      <td>332.024</td>\n",
       "      <td>Consommez moins, consommez mieux Un cahier pra...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Biens de consommation durables, Consommation ...</td>\n",
       "      <td>[Biens de consommation durables, Consommation,...</td>\n",
       "      <td>[consomm, consomm, mieux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169662</th>\n",
       "      <td>268999953</td>\n",
       "      <td>Le langage perdu des plantes : avez-vous déjà ...</td>\n",
       "      <td>L'auteur appelle à délaisser les médicaments i...</td>\n",
       "      <td>Phytothérapie;Plantes médicinales;Pollution mé...</td>\n",
       "      <td>363.7</td>\n",
       "      <td>Le langage perdu des plantes : avez-vous déjà ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Phytothérapie, Plantes médicinales, Pollution...</td>\n",
       "      <td>[Phytothérapie, Plantes médicinales, Pollution...</td>\n",
       "      <td>[langag, perdu, plant, avez-vous, goût, l'eau,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154508 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PPN                                              TITRE  \\\n",
       "0       000002364                              La culture pour vivre   \n",
       "1       000014877  La nuit, le jour : essai psychanalytique sur l...   \n",
       "2       000021857                                 Ruptures, cultures   \n",
       "3       00002564X                          La révolution structurale   \n",
       "4       000026352                           La Destruction du temple   \n",
       "...           ...                                                ...   \n",
       "169658  26899885X  Blablabla : en finir avec le bavardage climatique   \n",
       "169659  268998884  Politique de transition écologique : Démocrati...   \n",
       "169660  268999066              Abécédaire : mots et rites d'ailleurs   \n",
       "169661  268999503                   Consommez moins, consommez mieux   \n",
       "169662  268999953  Le langage perdu des plantes : avez-vous déjà ...   \n",
       "\n",
       "                                                   RESUME  \\\n",
       "0       Mort de la culture populaire en France. Mutati...   \n",
       "1       Discontinuité, latence, rétablissement d’une c...   \n",
       "2       Il faut imaginer Robinson sur son île, au mome...   \n",
       "3       Mutations ou crises, les brusques accès de fiè...   \n",
       "4       Oswald tire sur Kennedy. Jusque-là, c'est bon,...   \n",
       "...                                                   ...   \n",
       "169658  Dans le brouhaha de nos conversations et de l'...   \n",
       "169659  La transition écologique est devenue une préoc...   \n",
       "169660  Je dédie cet abécédaire des concepts des cultu...   \n",
       "169661  Un cahier pratique et ludique à remplir soi-mê...   \n",
       "169662  L'auteur appelle à délaisser les médicaments i...   \n",
       "\n",
       "                                                   RAMEAU    DEWEY  \\\n",
       "0       Culture populaire;Diffusion de la culture;Poli...      840   \n",
       "1               Complexe de castration;Psychanalyse;Rêves   154.63   \n",
       "2                                                 Culture      840   \n",
       "3                                          Structuralisme      100   \n",
       "4       Science-fiction américaine -- Traductions fran...      830   \n",
       "...                                                   ...      ...   \n",
       "169658                 Réchauffement de la Terre;Écologie            \n",
       "169659  Aménagement du territoire;Marchés publics;Tran...            \n",
       "169660  Ethnopsychiatrie;Psychanalyse et ésotérisme;Ri...            \n",
       "169661  Biens de consommation durables;Consommation --...  332.024   \n",
       "169662  Phytothérapie;Plantes médicinales;Pollution mé...    363.7   \n",
       "\n",
       "                                                    DESCR  \\\n",
       "0       La culture pour vivre Mort de la culture popul...   \n",
       "1       La nuit, le jour : essai psychanalytique sur l...   \n",
       "2       Ruptures, cultures Il faut imaginer Robinson s...   \n",
       "3       La révolution structurale Mutations ou crises,...   \n",
       "4       La Destruction du temple Oswald tire sur Kenne...   \n",
       "...                                                   ...   \n",
       "169658  Blablabla : en finir avec le bavardage climati...   \n",
       "169659  Politique de transition écologique : Démocrati...   \n",
       "169660  Abécédaire : mots et rites d'ailleurs Je dédie...   \n",
       "169661  Consommez moins, consommez mieux Un cahier pra...   \n",
       "169662  Le langage perdu des plantes : avez-vous déjà ...   \n",
       "\n",
       "        presence_chaine_indexation  \\\n",
       "0                            False   \n",
       "1                            False   \n",
       "2                            False   \n",
       "3                            False   \n",
       "4                             True   \n",
       "...                            ...   \n",
       "169658                       False   \n",
       "169659                        True   \n",
       "169660                       False   \n",
       "169661                        True   \n",
       "169662                       False   \n",
       "\n",
       "                                     rameau_chaines_index  \\\n",
       "0       [Culture populaire, Diffusion de la culture, P...   \n",
       "1           [Complexe de castration, Psychanalyse, Rêves]   \n",
       "2                                               [Culture]   \n",
       "3                                        [Structuralisme]   \n",
       "4       [Science-fiction américaine -- Traductions fra...   \n",
       "...                                                   ...   \n",
       "169658              [Réchauffement de la Terre, Écologie]   \n",
       "169659  [Aménagement du territoire, Marchés publics, T...   \n",
       "169660  [Ethnopsychiatrie, Psychanalyse et ésotérisme,...   \n",
       "169661  [Biens de consommation durables, Consommation ...   \n",
       "169662  [Phytothérapie, Plantes médicinales, Pollution...   \n",
       "\n",
       "                                          rameau_concepts  \\\n",
       "0       [Culture populaire, Diffusion de la culture, P...   \n",
       "1           [Complexe de castration, Psychanalyse, Rêves]   \n",
       "2                                               [Culture]   \n",
       "3                                        [Structuralisme]   \n",
       "4       [Science-fiction américaine, Traductions franç...   \n",
       "...                                                   ...   \n",
       "169658              [Réchauffement de la Terre, Écologie]   \n",
       "169659  [Aménagement du territoire, Marchés publics, T...   \n",
       "169660  [Ethnopsychiatrie, Psychanalyse et ésotérisme,...   \n",
       "169661  [Biens de consommation durables, Consommation,...   \n",
       "169662  [Phytothérapie, Plantes médicinales, Pollution...   \n",
       "\n",
       "                                          TITRE_processed  \n",
       "0                                          [cultur, vivr]  \n",
       "1       [nuit, jour, essai, psychanalyt, fonction, men...  \n",
       "2                                        [ruptur, cultur]  \n",
       "3                                    [révolu, structural]  \n",
       "4                                       [destruct, templ]  \n",
       "...                                                   ...  \n",
       "169658                  [blablabl, fin, bavardag, climat]  \n",
       "169659  [polit, transit, écolog, démocrat, droit, financ]  \n",
       "169660                   [abécédair, mot, rit, d'ailleur]  \n",
       "169661                          [consomm, consomm, mieux]  \n",
       "169662  [langag, perdu, plant, avez-vous, goût, l'eau,...  \n",
       "\n",
       "[154508 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add words\n",
    "add_words = [\n",
    "        \"la\",\n",
    "        \"de\",\n",
    "        \"le\",\n",
    "        \"les\",\n",
    "        \"l\",\n",
    "        \"au\",\n",
    "        \"du\"\n",
    "]\n",
    "\n",
    "process = PreprocessData(\n",
    "    df = df,\n",
    "    input_col=\"TITRE\",\n",
    "    output_col=\"TITRE_processed\",\n",
    "    add_words = add_words,\n",
    "    encod = None,\n",
    "    numeric = False,\n",
    "    stopw = True,\n",
    "    stem = False,\n",
    "    lem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df\n",
    "df = process.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre brut: \n",
      " Origines et symbolisme des productions textiles : de la toile et du fil\n",
      "\n",
      "Titre après processing :\n",
      " ['origine', 'symbolism', 'production', 'textile', 'toile', 'fil']\n"
     ]
    }
   ],
   "source": [
    "# Exemple\n",
    "idx = 300\n",
    "print(\"Titre brut: \\n\", df['TITRE'].iloc[idx])\n",
    "print(\"\\nTitre après processing :\\n\", df['TITRE_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_wordcloud(df[\u001b[39m'\u001b[39;49m\u001b[39mTITRE_processed\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\aurel\\OneDrive - rl conseils\\ABES_2023\\labo-indexationauto\\utils_visualization.py:36\u001b[0m, in \u001b[0;36mplot_wordcloud\u001b[1;34m(keywords, backgound_color, figsize, width, height, save_file)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_wordcloud\u001b[39m(\n\u001b[0;32m     25\u001b[0m     keywords,\n\u001b[0;32m     26\u001b[0m     backgound_color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     save_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     ):\n\u001b[0;32m     33\u001b[0m     plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39mfigsize)\n\u001b[0;32m     34\u001b[0m     wordcloud \u001b[39m=\u001b[39m WordCloud(\n\u001b[0;32m     35\u001b[0m         width\u001b[39m=\u001b[39mwidth, height\u001b[39m=\u001b[39mheight,\n\u001b[1;32m---> 36\u001b[0m         background_color\u001b[39m=\u001b[39mbackgound_color)\u001b[39m.\u001b[39mgenerate_from_frequencies(Counter(keywords))\n\u001b[0;32m     37\u001b[0m     plt\u001b[39m.\u001b[39mimshow(wordcloud)\n\u001b[0;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m save_file:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\collections\\__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[39mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m--> 577\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(iterable, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\collections\\__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mupdate(iterable)\n\u001b[0;32m    669\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m         _count_elements(\u001b[39mself\u001b[39;49m, iterable)\n\u001b[0;32m    671\u001b[0m \u001b[39mif\u001b[39;00m kwds:\n\u001b[0;32m    672\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_wordcloud(df['TITRE_processed'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des topics (pyLDAvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vizualisation\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Vectorization\u001b[39;00m\n\u001b[0;32m      2\u001b[0m feature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTITRE_processed\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m cv_transform \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(df[feature])\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDimensions de la matrice\u001b[39m\u001b[39m\"\u001b[39m, cv_transform\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2121\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2116\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2117\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2118\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2119\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2120\u001b[0m )\n\u001b[1;32m-> 2121\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2123\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             )\n\u001b[0;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1264\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1263\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1264\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1265\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1266\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\abes_index\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Vectorization\n",
    "feature = 'TITRE_processed'\n",
    "cv_transform = vectorizer.fit_transform(df[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, vectorizer)\n",
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_titres_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des résumés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des résumés\n",
    "process = PreprocessData(\n",
    "    df = df,\n",
    "    input_col=\"RESUME\",\n",
    "    output_col=\"RESUME_processed\",\n",
    "    add_words=add_words,\n",
    "    numeric=False,\n",
    "    stopw=True,\n",
    "    stem=False,\n",
    "    lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df\n",
    "df = process.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 12945\n",
    "print(\"Résumé brut: \\n\", df['RESUME'].iloc[idx])\n",
    "print(\"\\nRésumé après processing :\\n\", df['RESUME_processed'].iloc[idx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df['RESUME_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'RESUME_processed'\n",
    "cv_transform = vectorizer.fit_transform(df[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualisation\n",
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, vectorizer)\n",
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_resumes_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des description (titre+ resumé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des descriptions\n",
    "process = PreprocessData(\n",
    "    df = df,\n",
    "    input_col=\"DESCR\",\n",
    "    output_col=\"DESCR_processed\",\n",
    "    add_words=add_words,\n",
    "    numeric=False,\n",
    "    stopw=True,\n",
    "    stem=False,\n",
    "    lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df\n",
    "df = process.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 6549\n",
    "print(\"Description brute: \\n\", df['DESCR'].iloc[idx])\n",
    "print(\"\\nDescription après processing :\\n\", df['DESCR_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df['DESCR_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'DESCR_processed'\n",
    "cv_transform = vectorizer.fit_transform(df[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualisation\n",
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, vectorizer)\n",
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_description_lemma.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
