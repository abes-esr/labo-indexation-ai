{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel text classification using BERT family\n",
    "\n",
    "from: \n",
    "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=Lk6Cq9duKBkA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from \n",
    "https://colab.research.google.com/drive/1ejBYmu0P5urzghoTTDB-GBUxpbUFX0Gz?usp=sharing#scrollTo=p5Iuv7q7Dtg_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelie/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# remove any unwanted garbage using the collector\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn \n",
    "import tqdm.notebook as tq\n",
    "import warnings\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import training_args, Trainer\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/aurelie/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Tue Jul 11 23:06:13 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  Off |\n",
      "|  0%   39C    P8    22W / 450W |   1451MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"/data\"\n",
    "output_path = path + \"/outputs\"\n",
    "fig_path = path + \"/figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdd400a4a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "os.environ[\"require_grad\"] = \"False\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  (125220, 103022)\n",
      "Test dataset:  (29227, 103022)\n",
      "Validation dataset:  (100, 103022)\n"
     ]
    }
   ],
   "source": [
    "## load data (takes around 1min30s)\n",
    "df_train = pd.read_pickle(os.path.join(data_path, \"train_dataset_for_DL.pkl\"))\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "df_test = pd.read_pickle(os.path.join(data_path, \"test_dataset_for_DL.pkl\"))\n",
    "print(\"Test dataset: \", df_test.shape)\n",
    "df_valid100 = pd.read_pickle(os.path.join(data_path, \"valid100_dataset_for_DL.pkl\"))\n",
    "print(\"Validation dataset: \", df_valid100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125220 entries, 0 to 125219\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "train dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29227 entries, 0 to 29226\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "ntest dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "validation dataset memory usage:  None\n"
     ]
    }
   ],
   "source": [
    "# Check memory space\n",
    "print(\"train dataset memory usage: \", df_train.info())\n",
    "print()\n",
    "print(\"ntest dataset memory usage: \", df_test.info())\n",
    "print()\n",
    "print(\"validation dataset memory usage: \", df_valid100.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['!Xóõ (langue)', '\"Sprach- und Sachatlas Italiens und der Südschweiz\"',\n",
      "       '\"Taalatlas van Noord- en Zuid-Nederland\"', ''?d', ''?ntokyo',\n",
      "       ''Are'are (peuple des îles Salomon)', ''Au keto',\n",
      "       ''Au keto, Musique d'', ''Au ni aau', ''Au ni aau, Musique d'',\n",
      "       ...\n",
      "       'évangéliaire de split', 'Ālāp', 'Ārbajo, Musique d'',\n",
      "       'Đinh pơng, Musique de', 'Ō-tsuzumi, Musique d'', 'ʿArūbi', 'Ḥawfi',\n",
      "       'Ṭhumrī', 'Ṭār (tambour), Musique de', 'descr'],\n",
      "      dtype='object', length=103022)\n"
     ]
    }
   ],
   "source": [
    "## Show columns\n",
    "print(\"Features: \", df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  La bataille mondiale des matières premières Dans le débat sur un nouvel ordre économique international, les marchés mondiaux des matières premières constituent un enjeu de première importance. Ils conditionnent largement les moyens de financement du développement de pays pauvres et sont un des lieux stratégiques où se joue l'indépendance des pays. L'auteur analyse d'abord les mécanismes et les acteurs des marchés libres, mettant en lumière les limites du jeu libéral de l'offre et de la demande. Son examen des divers systèmes de régulation qui ont été expérimentés l'amènent ensuite à émettre de sérieuses réserves sur l'efficacité des stocks régulateurs. De même, les accords compensatoires (type prêts du FMI) se heurtent-ils à des difficultés théoriques et concrètes de mise en place. La régulation de l'offre n'a véritablement réussi que dans le cas du pétrole. Des solutions plus radicales existent en dehors d'un fonctionnement aménagé du marché : ouverture unilatérale des frontières pour certains produits ; indexation des prix, maîtrise des circuits de transformation et commercialisation. Toutes solutions qui supposent une modification profonde des règles des échanges internationaux. [4e de couv.]\n",
      "Concepts:  {'Matières premières': 1, 'Relations économiques internationales': 1}\n"
     ]
    }
   ],
   "source": [
    "# get one row\n",
    "row_id = 64\n",
    "label_cols = df_train.columns[:-1]\n",
    "sample_row = df_train.iloc[row_id]\n",
    "sample_descr = sample_row.descr\n",
    "sample_labels = sample_row[label_cols]\n",
    "\n",
    "print(\"Description: \", sample_descr)\n",
    "print(\"Concepts: \", sample_labels[sample_labels != 0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sample datasets\\ndf_train = df_train.sample(n=10000, random_state=42)\\nprint(\"Train dataset: \", df_train.shape)\\n#df_test = df_test.sample(n=3000, random_state=42)\\nprint(\"Test dataset: \", df_test.shape)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Sample datasets\n",
    "df_train = df_train.sample(n=10000, random_state=42)\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "#df_test = df_test.sample(n=3000, random_state=42)\n",
    "print(\"Test dataset: \", df_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Remove useless columns (labels not used in train dataset - Takes > 5min)\\ncols_to_remove = df_train.columns[df_train.sum() == 0]\\nlen(cols_to_remove)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Remove useless columns (labels not used in train dataset - Takes > 5min)\n",
    "cols_to_remove = df_train.columns[df_train.sum() == 0]\n",
    "len(cols_to_remove)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Remove useless columns\\ndf_train = df_train.drop(columns=cols_to_remove)\\nprint(\"Train dataset:\", df_train.shape)\\ndf_test = df_test.drop(columns=cols_to_remove)\\nprint(\"Test dataset:\", df_test.shape)\\ndf_valid100 = df_valid100.drop(columns=cols_to_remove)\\nprint(\"Validation dataset:\", df_valid100.shape)\\nlabel_cols = df_train.columns[:-1]\\nprint(\"Nombre de labels:\", len(label_cols))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Remove useless columns\n",
    "df_train = df_train.drop(columns=cols_to_remove)\n",
    "print(\"Train dataset:\", df_train.shape)\n",
    "df_test = df_test.drop(columns=cols_to_remove)\n",
    "print(\"Test dataset:\", df_test.shape)\n",
    "df_valid100 = df_valid100.drop(columns=cols_to_remove)\n",
    "print(\"Validation dataset:\", df_valid100.shape)\n",
    "label_cols = df_train.columns[:-1]\n",
    "print(\"Nombre de labels:\", len(label_cols))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93915, 103022) (31305, 103022)\n"
     ]
    }
   ],
   "source": [
    "# Separate train dataset into train and validation sets for model \n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_val = train_test_split(df_train, test_size = 0.25)\n",
    "print(data_train.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103021\n"
     ]
    }
   ],
   "source": [
    "LABEL_COLUMNS = data_train.columns[:-1]\n",
    "id2label = {idx:label for idx, label in enumerate(LABEL_COLUMNS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABEL_COLUMNS)}\n",
    "print(len(LABEL_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Histoire                            4539\n",
       "Aspect social                       1599\n",
       "Manuels d'enseignement supérieur    1213\n",
       "Français (langue)                   1194\n",
       "Philosophie                         1133\n",
       "Mathématiques                       1053\n",
       "Étude et enseignement (primaire)    1047\n",
       "Étude et enseignement                994\n",
       "Droit                                936\n",
       "Bandes dessinées                     928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[LABEL_COLUMNS].sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sample test_set\\ndata_test = df_test.sample(n=5000)\\nprint(\"data_test shape:\", data_test.shape)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Sample test_set\n",
    "data_test = df_test.sample(n=5000)\n",
    "print(\"data_test shape:\", data_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(label_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enfants perdus de Roumanie : histoire des orphelinats de Ceausescu Images d'enfants maltraités, mal nourris, privés d'accès aux soins, entassés dans des bâtisses insalubres : en 1989, l'opinion internationale découvrait avec effroi l'enfer des « orphelinats de Ceausescu », au point que leur démantèlement fut une condition sine qua non de l'adhésion de la Roumanie à l'Union européenne. Au-delà des représentations sensationnalistes diffusées par la presse et les organisations internationales, la réalité de ce phénomène reste encore largement méconnue. Une certitude : du fait d'un manque cruel de moyens et de personnel qualifié, ces « enfants de l'État » ont, par dizaines de milliers, subi pendant des années, sans possibilité d'échappatoire, la rudesse des conditions de vie sous le régime socialiste et une violence quotidienne au sein des institutions censées les prendre en charge. En s'appuyant sur des sources nationales et locales inexplorées, sur de nombreux témoignages d'anciens mineurs placés, mais aussi sur ses douze années d'observation et de travail social sur le terrain, Jean-Philippe Légaut nous montre pourquoi et comment ces structures ont condamné ceux qu'elles auraient dû protéger.\n",
      "{'Enfants abandonnés': 1, 'Orphelinats': 1, 'Politique publique': 1}\n"
     ]
    }
   ],
   "source": [
    "# Select one example\n",
    "id = 56\n",
    "sample_row = data_train.iloc[id]\n",
    "sample_text = sample_row.descr\n",
    "sample_labels = sample_row[LABEL_COLUMNS][sample_row[LABEL_COLUMNS] == 1 ]\n",
    "print(sample_text)\n",
    "print(sample_labels.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "model_name = 'camembert-base'\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item_idx: int):\n",
    "        data_row = self.data.iloc[item_idx]\n",
    "        descr = data_row.descr\n",
    "        descr = \" \".join(descr.split())\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "\n",
    "        # Tokenization\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=False,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        #attention_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            #'description': descr,\n",
    "            'input_ids': input_ids ,\n",
    "            #'attention_mask': attention_mask,\n",
    "            'labels':torch.FloatTensor(labels)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "training_set = RameauLabelDataset(data_train, tokenizer, MAX_LEN)\n",
    "validation_set = RameauLabelDataset(data_val, tokenizer, MAX_LEN)\n",
    "testing_set = RameauLabelDataset(df_test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'pin_memory': True,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 12\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "               'pin_memory': True, \n",
    "               'shuffle': False,\n",
    "               'num_workers': 12\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **test_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoModelForSequenceClassification\\n\\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\\nmodel.to(device)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\n",
    "model.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): CamembertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=103021, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = CamembertModel.from_pretrained(model_name, return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, len(label_cols))\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        output = self.bert_model(input_ids)\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loo^p\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs = data['input_ids'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('camembert_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model on gpu\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create defait learning rate scheduler from Trainer\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 10\n",
    "batch_per_epoch = 30\n",
    "num_training_steps = num_epochs * batch_per_epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for i, batch in enumerate(training_loader,0):\n",
    "    while i < batch_per_epoch:\n",
    "        for epoch in range(num_epochs):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1_score\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "  \n",
    "    ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "    outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(outputs, targets)\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for data in training_loader:\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch)\n",
    "        \n",
    "\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training time: {stop - start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['labels'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "      predictions - \n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    \n",
    "    descr = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    target_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for data in data_loader:\n",
    "        #descr = data[\"descr\"]\n",
    "        ids = data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "        targets = data[\"labels\"].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
    "        outputs = torch.sigmoid(outputs).detach().cpu()\n",
    "        # thresholding at 0.5\n",
    "        preds = outputs.round()\n",
    "        targets = targets.detach().cpu()\n",
    "\n",
    "        descr.extend(descr)\n",
    "        predictions.extend(preds)\n",
    "        prediction_probs.extend(outputs)\n",
    "        target_values.extend(targets)\n",
    "    \n",
    "    predictions = torch.stack(predictions)\n",
    "    prediction_probs = torch.stack(prediction_probs)\n",
    "    target_values = torch.stack(target_values)\n",
    "    \n",
    "    return predictions, prediction_probs, target_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_metrics import *\n",
    "THRESHOLD = 0.05\n",
    "for epoch in range(EPOCHS):\n",
    "    outputs_prob, targets = validation(epoch)\n",
    "    outputs = np.array(outputs_prob) >= THRESHOLD\n",
    "    results = label_metrics_report(\n",
    "        modelName = model_name,\n",
    "        y_true = targets,\n",
    "        y_pred = outputs,\n",
    "        y_prob=None,\n",
    "        print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = outputs[0]\n",
    "t[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY CAMEMBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item_idx: int):\n",
    "        data_row = self.data.iloc[item_idx]\n",
    "        descr = data_row.descr\n",
    "        descr = \" \".join(descr.split())\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "\n",
    "        # Tokenization\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            #'description': descr,\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'labels':torch.FloatTensor(labels)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "train_dataset = RameauLabelDataset(data_train, tokenizer)\n",
    "sample_item = train_dataset[0]\n",
    "print(\"keys:\", sample_item.keys())\n",
    "#print(\"description:\", sample_item[\"description\"])\n",
    "print(\"labels:\", sample_item[\"labels\"])\n",
    "print(sample_item[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-05\n",
    "THRESHOLD = 0.08 # threshold for the sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Module\n",
    "class RameauLabelDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, val_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = RameauLabelDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "            \n",
    "        self.val_dataset = RameauLabelDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        self.test_dataset = RameauLabelDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the data_module\n",
    "data_module = RameauLabelDataModule(\n",
    "    data_train, \n",
    "    data_val, \n",
    "    df_test, \n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_len = MAX_LEN)\n",
    "\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class RameauLabelClassifier(pl.LightningModule):\n",
    "  # Set up the classifier\n",
    "  def __init__(self, config: dict):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.pretrained_model = CamembertModel.from_pretrained(config['model_name'], return_dict = True)\n",
    "    self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "    self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
    "    self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    self.dropout = nn.Dropout()  \n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    # roberta layer\n",
    "    output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "    # final logits\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "    pooled_output = self.hidden(pooled_output)\n",
    "    pooled_output = F.relu(pooled_output)\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "    logits = self.classifier(pooled_output)\n",
    "    # calculate loss\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "      loss = self.loss_func(logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
    "\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    self.log(\"train loss \", loss, prog_bar = True, logger=True)\n",
    "    return {\"loss\":loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "  def validation_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    self.log(\"validation loss \", loss, prog_bar = True, logger=True)\n",
    "    return {\"val_loss\": loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "  def predict_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    return outputs\n",
    "  \n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
    "    total_steps = self.config['train_size']/self.config['batch_size']\n",
    "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    return [optimizer],[scheduler]\n",
    "\n",
    "  # def on_validation_epoch_end(self, outputs):\n",
    "  #   losses = []\n",
    "  #   for output in outputs:\n",
    "  #     loss = output['val_loss'].detach().cpu()\n",
    "  #     losses.append(loss)\n",
    "  #   avg_loss = torch.mean(torch.stack(losses))\n",
    "  #   self.log(\"avg_val_loss\", avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': model_name,\n",
    "    'n_labels': n_labels,\n",
    "    'batch_size': 128,\n",
    "    'max_len': 256,\n",
    "    'lr': 1.5e-6,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(data_module.train_dataloader()),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 100\n",
    "}\n",
    "\n",
    "model = RameauLabelClassifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "sample_item = train_dataset[idx]\n",
    "input_ids = sample_item[\"input_ids\"]\n",
    "attention_mask = sample_item['attention_mask']\n",
    "labels = sample_item['labels']\n",
    "model.cpu()\n",
    "loss, output = model(input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), labels.unsqueeze(dim=0))\n",
    "print(labels.shape, output.shape, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule\n",
    "data_module = data_module = RameauLabelDataModule(\n",
    "    data_train, \n",
    "    data_val, \n",
    "    df_test, \n",
    "    tokenizer,\n",
    "    batch_size=config['batch_size'],\n",
    "    max_token_len = config[\"max_len\"])\n",
    "\n",
    "data_module.setup() \n",
    "\n",
    "# model\n",
    "model = RameauLabelClassifier(config)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trainer and fit\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\", num_sanity_val_steps=50)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to convert list of comments into predictions for each comment\n",
    "def classify_raw_comments(model, dm):\n",
    "  predictions = trainer.predict(model, datamodule=dm)\n",
    "  flattened_predictions = np.stack([torch.sigmoid(torch.Tensor(p)) for batch in predictions for p in batch])\n",
    "  return flattened_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classify_raw_comments(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(df_train) // BATCH_SIZE\n",
    "print(\"steps per epoch:\", steps_per_epoch)\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "print(\"Total training steps:\", total_training_steps)\n",
    "warmup_steps = total_training_steps // 5\n",
    "print(\"Warmup steps: \", warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = RameauLabelClassifier(\n",
    "  n_classes=len(LABEL_COLUMNS),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=N_EPOCHS, accelerator=\"auto\", enable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the current model\n",
    "model = RameauLabelClassifier(\n",
    "  n_classes=len(label_cols),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves a file like: input/QTag-epoch=02-val_loss=0.32.ckpt\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    monitor='val_loss',# monitored quantity\n",
    "    filename='Rameau_BertMultilingualClassifier-{epoch:02d}-{val_loss:.2f}',\n",
    "    verbose=True,\n",
    "    save_top_k=3, #  save the top 3 models\n",
    "    mode='min', # mode of the monitored quantity  for optimization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the progress in Tensorboard\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"Bert_multilingual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = pl.Trainer(\n",
    "  logger=logger,\n",
    "  callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "  max_epochs=EPOCHS,\n",
    "  accelerator=\"gpu\",\n",
    "  enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "N_EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 300\n",
    "LR = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs =EPOCHS ,  accelerator=\"gpu\", callbacks=[checkpoint_callback], enable_progress_bar=True)\n",
    "# Train the Classifier Model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"./checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"test_loss\",\n",
    "  mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "trained_model = RameauLabelTagger.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_classes=len(label_cols)\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "MAX_TOKEN_COUNT = 512\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "val_dataset = RameauLabelDataset(\n",
    "  df_valid100,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "  _, prediction = trained_model(\n",
    "    item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "  )\n",
    "  predictions.append(prediction.flatten())\n",
    "  labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "THRESHOLD = 0.7\n",
    "torchmetrics.Accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC\n",
    "print(\"AUROC per tag\")\n",
    "for i, name in enumerate(label_cols):\n",
    "  tag_auroc = torchmetrics.AUROC(predictions[:, i], labels[:, i], pos_label=1)\n",
    "  print(f\"{name}: {tag_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "upper, lower = 1, 0\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true,\n",
    "  y_pred,\n",
    "  target_names=label_cols,\n",
    "  zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abes_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "79d7ff32004ac4c5bc1812f118fca289ef6cc0cea24529fb05e42e57e2fccd5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
