{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:47:23.872042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 22:47:24.456178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# remove any unwanted garbage using the collector\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import tqdm.notebook as tq\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aurelie/ABES/labo-indexation-ai/DeepLearning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \"/home/aurelie/ABES/labo-indexation-ai\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"/data\"\n",
    "output_path = path + \"/outputs\"\n",
    "fig_path = path + \"/figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aurelie/ABES/labo-indexation-ai'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/aurelie/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Wed Jul 26 22:47:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  Off |\n",
      "| 30%   37C    P2    65W / 450W |  24197MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU \n",
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://curiousily.com/posts/multi-label-text-classification-with-bert-and-pytorch-lightning/\n",
    "https://www.youtube.com/watch?v=vNKIg8rXK6w&ab_channel=rupertai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup torch\n",
    "# Setup torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  (125220, 103022)\n",
      "Test dataset:  (29227, 103022)\n",
      "Validation dataset:  (100, 103022)\n"
     ]
    }
   ],
   "source": [
    "## load data (takes around 1min30s)\n",
    "df_train = pd.read_pickle(os.path.join(data_path, \"train_dataset_for_DL.pkl\"))\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "df_test = pd.read_pickle(os.path.join(data_path, \"test_dataset_for_DL.pkl\"))\n",
    "print(\"Test dataset: \", df_test.shape)\n",
    "df_valid100 = pd.read_pickle(os.path.join(data_path, \"valid100_dataset_for_DL.pkl\"))\n",
    "print(\"Validation dataset: \", df_valid100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125220 entries, 0 to 125219\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "train dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29227 entries, 0 to 29226\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "ntest dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "validation dataset memory usage:  None\n"
     ]
    }
   ],
   "source": [
    "# Check memory space\n",
    "print(\"train dataset memory usage: \", df_train.info())\n",
    "print()\n",
    "print(\"ntest dataset memory usage: \", df_test.info())\n",
    "print()\n",
    "print(\"validation dataset memory usage: \", df_valid100.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  La bataille mondiale des matières premières Dans le débat sur un nouvel ordre économique international, les marchés mondiaux des matières premières constituent un enjeu de première importance. Ils conditionnent largement les moyens de financement du développement de pays pauvres et sont un des lieux stratégiques où se joue l'indépendance des pays. L'auteur analyse d'abord les mécanismes et les acteurs des marchés libres, mettant en lumière les limites du jeu libéral de l'offre et de la demande. Son examen des divers systèmes de régulation qui ont été expérimentés l'amènent ensuite à émettre de sérieuses réserves sur l'efficacité des stocks régulateurs. De même, les accords compensatoires (type prêts du FMI) se heurtent-ils à des difficultés théoriques et concrètes de mise en place. La régulation de l'offre n'a véritablement réussi que dans le cas du pétrole. Des solutions plus radicales existent en dehors d'un fonctionnement aménagé du marché : ouverture unilatérale des frontières pour certains produits ; indexation des prix, maîtrise des circuits de transformation et commercialisation. Toutes solutions qui supposent une modification profonde des règles des échanges internationaux. [4e de couv.]\n",
      "Concepts:  {'Matières premières': 1, 'Relations économiques internationales': 1}\n"
     ]
    }
   ],
   "source": [
    "# get one row\n",
    "row_id = 64\n",
    "label_cols = df_train.columns[:-1]\n",
    "sample_row = df_train.iloc[row_id]\n",
    "sample_descr = sample_row.descr\n",
    "sample_labels = sample_row[label_cols]\n",
    "\n",
    "print(\"Description: \", sample_descr)\n",
    "print(\"Concepts: \", sample_labels[sample_labels != 0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "sampling=False\n",
    "N_TRAIN_SAMPLE = 5000\n",
    "N_TEST_SAMPLE = 500\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-05\n",
    "THRESHOLD = 0.2 # threshold to convert proba into predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  (125220, 103022)\n",
      "Test dataset:  (29227, 103022)\n"
     ]
    }
   ],
   "source": [
    "if sampling: \n",
    "    # Sample datasets\n",
    "    df_train = df_train.sample(n=N_TRAIN_SAMPLE, random_state=42)   \n",
    "    df_test = df_test.sample(n=N_TEST_SAMPLE, random_state=42)\n",
    "\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "print(\"Test dataset: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87654, 103022) (37566, 103022)\n"
     ]
    }
   ],
   "source": [
    "# Separate train dataset into train and validation sets for model \n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(df_train, test_size = 0.3)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Build Deep Learning Model with BERT/PyTorch\n",
    "import torch\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "modelname = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizer.from_pretrained(modelname)\n",
    "bert_model = CamembertModel.from_pretrained(modelname, return_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "text_example = 'Je regarderai la serie à la télévision avec mes enfants ce soir'\n",
    "# Generate encoding\n",
    "encodings = tokenizer.encode_plus(\n",
    "    text_example,\n",
    "    add_special_tokens=True,\n",
    "    max_length=20,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Encodings generate a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html)\n",
    "print(encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: tokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        descr = \" \".join(data_row.descr.split())\n",
    "        labels = data_row[label_cols]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            \"labels\": torch.FloatTensor(labels),\n",
    "            \"descr\": descr\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all datasets\n",
    "train_dataset = RameauLabelDataset(\n",
    "  df_train,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_LEN\n",
    ")\n",
    "test_dataset = RameauLabelDataset(\n",
    "  df_test,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_LEN\n",
    ")\n",
    "valid_dataset = RameauLabelDataset(\n",
    "  df_valid100,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  La culture pour vivre Mort de la culture populaire en France. Mutation des institutions culturelles grâce à une technique de mise en relation des oeuvres et d'un public, et qui tend à créer un comportement culturel adapté aux caractéristiques de l'époque\n",
      "Labels:  tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Shape:  torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Check on an item from the dataset\n",
    "train_dataset = RameauLabelDataset(\n",
    "  df_train,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_LEN\n",
    ")\n",
    "sample_item = train_dataset[0]\n",
    "\n",
    "print(\"Description: \", sample_item[\"descr\"])\n",
    "print(\"Labels: \", sample_item[\"labels\"])\n",
    "print(\"Shape: \", sample_item[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    5,    61,  1030,    24,   747,  8527,     8,    13,  1030,  2429,\n",
       "            22,   184,     9, 16003,   472,    20,  3847,  5993,   435,    15,\n",
       "            28,   899,     8,   375,    22,   911,    20,  6737,    14,    18,\n",
       "            11,    59,   525,     7,    14,    31,  4769,    15,   739,    23,\n",
       "          2379,  3542,  2740,    68,  1830,    10,     8,    17,    11,  1475,\n",
       "             6,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'descr': \"La culture pour vivre Mort de la culture populaire en France. Mutation des institutions culturelles grâce à une technique de mise en relation des oeuvres et d'un public, et qui tend à créer un comportement culturel adapté aux caractéristiques de l'époque\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data loaders\n",
    "train_data_loader = DataLoader(train_dataset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(valid_dataset, \n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(768, len(label_cols))\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m BERTClass()\n\u001b[1;32m      3\u001b[0m \u001b[39m#model.to(\"cpu\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and load it to GPU\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, training_loader, optimizer, criterion):\n",
    "\n",
    "    # set model to training mode (activate dropout, batch norm)\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), \n",
    "                      leave=True, colour='steelblue')\n",
    "    \n",
    "    for batch_idx, data in loop:\n",
    "        counter += 1\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        labels = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(ids, mask, token_type_ids) \n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "        # calculate the accuracy\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        #upper, lower = 1, 0\n",
    "        #preds = np.where(outputs > THRESHOLD, upper, lower)\n",
    "        preds = outputs.round() # thresholding at 0.5\n",
    "        train_running_correct += precision_score(preds.detach().cpu(), labels.detach().cpu(), average=\"samples\")\n",
    "\n",
    "        # backpropagation\n",
    "        #optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # update the optimizer parameter\n",
    "        optimizer.step()\n",
    "\n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_prec = train_running_correct / counter\n",
    "\n",
    "    return epoch_loss, epoch_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def validate(model, validation_loader, criterion):\n",
    "    \n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "\n",
    "    valid_loop = tq.tqdm(enumerate(validation_loader), total=len(validation_loader), \n",
    "                      leave=True, colour='green')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in valid_loop:\n",
    "            counter += 1\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            labels = data[\"labels\"].to(device, dtype = torch.float)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            #upper, lower = 1, 0\n",
    "            #preds = np.where(outputs > THRESHOLD, upper, lower)\n",
    "            preds = outputs.round() # thresholding at 0.5\n",
    "            valid_running_correct += precision_score(preds.detach().cpu(), labels.detach().cpu(), average=\"samples\")\n",
    "\n",
    "\n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_prec = valid_running_correct / counter\n",
    "    return epoch_loss, epoch_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, model, optimizer, criterion\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, 'DeepLearning/outputs/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to save the trained model to disk.\n",
    "    \"\"\"\n",
    "    print(f\"Saving final model...\")\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, 'DeepLearning/outputs/final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(train_prec, valid_prec, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    # accuracy plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_prec, color='green', linestyle='-', \n",
    "        label='train precision'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_prec, color='blue', linestyle='-', \n",
    "        label='validation precision'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig('DeepLearning/outputs/precision.png')\n",
    "    \n",
    "    # loss plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('DeepLearning/outputs/loss.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training1\n",
    "https://github.com/dtolk/multilabel-BERT/blob/master/notebooks/multi_label_text_classification_BERT.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://debuggercafe.com/saving-and-loading-the-best-model-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize SaveBestModel class\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to keep track of losses and accuracies\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "\n",
    "# start the training\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {EPOCHS}\")\n",
    "    train_epoch_loss, train_epoch_acc = train_model(model, train_data_loader, \n",
    "                                            optimizer, criterion)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(model, val_data_loader,  \n",
    "                                                criterion)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training precision: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation precision: {valid_epoch_acc:.3f}\")\n",
    "    # save the best model till now if we have the least loss in the current epoch\n",
    "    save_best_model(\n",
    "        valid_epoch_loss, epoch, model, optimizer, criterion\n",
    "    )\n",
    "    print('-'*50)\n",
    "    \n",
    "# save the trained model weights for a final time\n",
    "save_model(EPOCHS, model, optimizer, criterion)\n",
    "# save the loss and accuracy plots\n",
    "save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
    "print('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model checkpoint\n",
    "best_model_cp = torch.load('DeepLearning/outputs/best_model.pth')\n",
    "best_model_epoch = best_model_cp['epoch']\n",
    "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")\n",
    "# load the last model checkpoint\n",
    "last_model_cp = torch.load('DeepLearning/outputs/final_model.pth')\n",
    "last_model_epoch = last_model_cp['epoch']\n",
    "print(f\"Last model was saved at {last_model_epoch} epochs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data_loader):\n",
    "    \"\"\"\n",
    "    Function to test the model\n",
    "    \"\"\"\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    print('Testing')\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "\n",
    "    test_loop = tq.tqdm(enumerate(test_data_loader), total=len(test_data_loader), \n",
    "                      leave=True, colour='green')\n",
    "    with torch.no_grad():\n",
    "        for i, data in test_loop:\n",
    "            counter += 1\n",
    "            \n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            labels = data[\"labels\"].to(device, dtype = torch.float)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            # calculate the accuracy\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            #upper, lower = 1, 0\n",
    "            #preds = np.where(outputs > THRESHOLD, upper, lower)\n",
    "            preds = outputs.round() # thresholding at 0.5\n",
    "            valid_running_correct += precision_score(preds.detach().cpu(), labels.detach().cpu(), average=\"samples\")\n",
    "                  \n",
    "    # Precision for the complete epoch\n",
    "    final_prec = valid_running_correct / counter\n",
    "    return final_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the last epoch saved model\n",
    "def test_last_model(model, checkpoint, test_loader):\n",
    "    print('Loading last epoch saved model weights...')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_acc = test(model, test_loader)\n",
    "    print(f\"Last epoch saved model accuracy: {test_acc:.3f}\")\n",
    "# test the best epoch saved model\n",
    "def test_best_model(model, checkpoint, test_loader):\n",
    "    print('Loading best epoch saved model weights...')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_acc = test(model, test_loader)\n",
    "    print(f\"Best epoch saved model accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_last_model(model, last_model_cp, test_data_loader)\n",
    "test_best_model(model, best_model_cp, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "      predictions - \n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    \n",
    "    descr = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    target_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for data in data_loader:\n",
    "        descr = data[\"descr\"]\n",
    "        ids = data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data[\"labels\"].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        # add sigmoid (for the training sigmoid is in BCEWithLogitsLoss)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # thresholding at 0.5\n",
    "        preds = outputs.round()\n",
    "\n",
    "        descr.extend(descr)\n",
    "        predictions.extend(preds)\n",
    "        prediction_probs.extend(outputs)\n",
    "        target_values.extend(targets)\n",
    "    \n",
    "    predictions = torch.stack(predictions)\n",
    "    prediction_probs = torch.stack(prediction_probs)\n",
    "    target_values = torch.stack(target_values)\n",
    "    \n",
    "    return descr, predictions, prediction_probs, target_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test dataset (~20min)\n",
    "descr, predictions, prediction_probs, target_values = get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access values\n",
    "prediction_probs = prediction_probs.detach().cpu().detach().numpy()\n",
    "predictions = predictions.detach().cpu().detach().numpy()\n",
    "target_values = target_values.detach().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical metrics\n",
    "print(\"Average doc precision : \", precision_score(target_values, predictions, average=\"samples\", zero_division=0))\n",
    "print(\"Average doc recall : \", recall_score(target_values, predictions, average=\"samples\", zero_division=0))\n",
    "print(\"Average doc F1score : \", f1_score(target_values, predictions, average=\"samples\", zero_division=0))\n",
    "print(\"Average doc Jaccard index : \", jaccard_score(target_values, predictions, average=\"samples\", zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = predictions\n",
    "y_true = target_values\n",
    "upper, lower = 1, 0\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true,\n",
    "  y_pred,\n",
    "  target_names=label_cols,\n",
    "  zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "idx = 458\n",
    "descriptions = test_data_loader.dataset.data.descr\n",
    "print(\"Description: \", descriptions.iloc[idx])\n",
    "pred_probs = print(\"Predicted Concept: \", label_cols[prediction_probs[idx] > 0.01])\n",
    "print(\"Sudoc Indexation: \", label_cols[target_values[idx] == 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abes_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "79d7ff32004ac4c5bc1812f118fca289ef6cc0cea24529fb05e42e57e2fccd5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
