{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import warnings\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://curiousily.com/posts/multi-label-text-classification-with-bert-and-pytorch-lightning/\n",
    "https://www.youtube.com/watch?v=vNKIg8rXK6w&ab_channel=rupertai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff266ef5f50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/aurelie/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Mon Jul  3 19:41:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  Off |\n",
      "|  0%   45C    P8    29W / 450W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"/data\"\n",
    "output_path = path + \"/outputs\"\n",
    "fig_path = path + \"/figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  (125264, 103022)\n",
      "Test dataset:  (29244, 103022)\n",
      "Validation dataset:  (100, 103022)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## load data (takes around 1min15s)\n",
    "df_train = pd.read_pickle(os.path.join(data_path, \"train_dataset_for_DL.pkl\"))\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "df_test = pd.read_pickle(os.path.join(data_path, \"test_dataset_for_DL.pkl\"))\n",
    "print(\"Test dataset: \", df_test.shape)\n",
    "df_valid100 = pd.read_pickle(os.path.join(data_path, \"valid100_dataset_for_DL.pkl\"))\n",
    "print(\"Validation dataset: \", df_valid100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['!Xóõ (langue)', '\"Sprach- und Sachatlas Italiens und der Südschweiz\"',\n",
       "       '\"Taalatlas van Noord- en Zuid-Nederland\"', ''?d', ''?ntokyo',\n",
       "       ''Are'are (peuple des îles Salomon)', ''Au keto',\n",
       "       ''Au keto, Musique d'', ''Au ni aau', ''Au ni aau, Musique d'',\n",
       "       ...\n",
       "       'évangéliaire de split', 'Ālāp', 'Ārbajo, Musique d'',\n",
       "       'Đinh pơng, Musique de', 'Ō-tsuzumi, Musique d'', 'ʿArūbi', 'Ḥawfi',\n",
       "       'Ṭhumrī', 'Ṭār (tambour), Musique de', 'descr'],\n",
       "      dtype='object', length=103022)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 103021 labels\n"
     ]
    }
   ],
   "source": [
    "# Get labels\n",
    "labels_list  = df_train.columns[:-1]\n",
    "print(f\"There are {len(labels_list )} labels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Deep Learning Model with CamemBERT/PyTorch\n",
    "from transformers import  AutoTokenizer\n",
    "MODEL_NAME = 'camembert-base'\n",
    "camembert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camembert tokenizer\n",
    "camembert_input = camembert_tokenizer(text_example, padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n",
    "print(camembert_input['input_ids'])\n",
    "print(camembert_input[\"input_ids\"].shape, bert_input[\"attention_mask\"].shape)\n",
    "print(camembert_input['attention_mask'])\n",
    "print(camembert_tokenizer.decode(camembert_input.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Deep Learning Model with CamemBERT/PyTorch\n",
    "from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "MODEL_NAME = 'camembert-base'\n",
    "camembert = CamembertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1086, in _get_module\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/trainer.py\", line 37, in <module>\n",
      "    from .integrations import (  # isort: split\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/integrations.py\", line 46, in <module>\n",
      "    from .trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 27, in <module>\n",
      "    from .training_args import TrainingArguments\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/training_args.py\", line 27, in <module>\n",
      "    from .utils import (\n",
      "ImportError: cannot import name 'torch_required' from 'transformers.utils' (/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/utils/__init__.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1982783/902497494.py\", line 8, in <module>\n",
      "    from fast_bert.data_lm import BertLMDataBunch\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/fast_bert/__init__.py\", line 14, in <module>\n",
      "    from .learner_ner import BertNERLearner\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/fast_bert/learner_ner.py\", line 11, in <module>\n",
      "    from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1076, in __getattr__\n",
      "  File \"/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1088, in _get_module\n",
      "RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "cannot import name 'torch_required' from 'transformers.utils' (/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/utils/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/aurelie/.local/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# remove any unwanted garbage using the collector\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# import fastbert's main classes\n",
    "from fast_bert.data_cls import BertDataBunch\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.data_lm import BertLMDataBunch\n",
    "from fast_bert.learner_lm import BertLMLearner\n",
    "from fast_bert.prediction import BertClassificationPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/labels.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create databuncj and learner for test classificaiton\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m databunch \u001b[39m=\u001b[39m BertDataBunch(data_path, \n\u001b[1;32m      3\u001b[0m                           data_path,\n\u001b[1;32m      4\u001b[0m                           tokenizer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcamembert-base\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                           train_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain_dataset_for_DL.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                           val_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest_dataset_for_DL.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                           label_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlabels.txt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m                           text_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdesc\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m                           label_col\u001b[39m=\u001b[39;49m labels_list,\n\u001b[1;32m     10\u001b[0m                           batch_size_per_gpu\u001b[39m=\u001b[39;49m\u001b[39m14\u001b[39;49m,    \n\u001b[1;32m     11\u001b[0m                           max_seq_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m                           multi_gpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     13\u001b[0m                           multi_label\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m                           model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcamembert-base\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/fast_bert/data_cls.py:427\u001b[0m, in \u001b[0;36mBertDataBunch.__init__\u001b[0;34m(self, data_dir, label_dir, tokenizer, train_file, val_file, test_data, label_file, text_col, label_col, batch_size_per_gpu, max_seq_length, multi_gpu, multi_label, backend, model_type, logger, clear_cache, no_cache, custom_sampler, pos_weight, weight)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     processor \u001b[39m=\u001b[39m TextProcessor(data_dir, label_dir)\n\u001b[0;32m--> 427\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39;49mget_labels(label_file)\n\u001b[1;32m    429\u001b[0m \u001b[39mif\u001b[39;00m train_file:\n\u001b[1;32m    430\u001b[0m     \u001b[39m# Train DataLoader\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     train_examples \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/fast_bert/data_cls.py:276\u001b[0m, in \u001b[0;36mTextProcessor.get_labels\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See base class.\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m--> 276\u001b[0m         pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_dir, filename), header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    277\u001b[0m         \u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m         \u001b[39m.\u001b[39mvalues\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/labels.txt'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create databuncj and learner for test classificaiton\n",
    "databunch = BertDataBunch(data_path, \n",
    "                          data_path,\n",
    "                          tokenizer='camembert-base',\n",
    "                          train_file='train_dataset_for_DL.csv',\n",
    "                          val_file='test_dataset_for_DL.csv',\n",
    "                          label_file='labels.txt',\n",
    "                          text_col='desc',\n",
    "                          label_col= labels_list,\n",
    "                          batch_size_per_gpu=14,    \n",
    "                          max_seq_length=512,\n",
    "                          multi_gpu=False,\n",
    "                          multi_label=True,\n",
    "                          model_type='camembert-base')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   5,  100, 1483,   73,   13,   48,  915,   15,   13, 2572,   42,  249,\n",
      "          329,   44,  619,    6,    1,    1,    1,    1]])\n",
      "torch.Size([1, 20]) torch.Size([1, 20])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "<s> Je regarderai la serie à la télévision avec mes enfants ce soir</s><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# Simple tokenizer\n",
    "text_example = 'Je regarderai la serie à la télévision avec mes enfants ce soir'\n",
    "tokenizer_output = tokenizer(text_example, padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n",
    "print(tokenizer_output['input_ids'])\n",
    "print(tokenizer_output[\"input_ids\"].shape, tokenizer_output[\"attention_mask\"].shape)\n",
    "print(tokenizer_output['attention_mask'])\n",
    "print(tokenizer.decode(tokenizer_output.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation de batches\n",
    "def tokenize_batch(samples, tokenizer):\n",
    "    text = [sample[\"descr\"] for sample in samples]\n",
    "    labels = torch.tensor([sample[mlb.classes_] for sample in samples])\n",
    "    str_labels = [sample[mlb.classes_] for sample in samples]\n",
    "    # The tokenizer handles\n",
    "    # - Tokenization (amazing right?)\n",
    "    # - Padding (adding empty tokens so that each example has the same length)\n",
    "    # - Truncation (cutting samples that are too long)\n",
    "    # - Special tokens (in CamemBERT, each sentence ends with a special token </s>)\n",
    "    # - Attention mask (a binary vector which tells the model which tokens to look at. For instance it will not compute anything if the token is a padding token)\n",
    "    tokens = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    return {\"input_ids\": tokens.input_ids, \"attention_mask\": tokens.attention_mask, \"labels\": labels, \"str_labels\": str_labels, \"sentences\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[1;32m      2\u001b[0m val_dataloader \u001b[39m=\u001b[39m DataLoader(df_valid100, collate_fn\u001b[39m=\u001b[39mfunctools\u001b[39m.\u001b[39mpartial(tokenize_batch, tokenizer\u001b[39m=\u001b[39mtokenizer), batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(val_dataloader))\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3760\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3761\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3762\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "val_dataloader = DataLoader(df_valid100, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer), batch_size=16)\n",
    "next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du model\n",
    "with torch.no_grad():\n",
    "    model_output = camembert(**tokenizer_output, output_hidden_states=True)\n",
    "    model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 32005])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "model_output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"La bataille mondiale des matières premières Dans le débat sur un nouvel ordre économique international, les marchés mondiaux des matières premières constituent un enjeu de première importance. Ils conditionnent largement les moyens de financement du développement de pays pauvres et sont un des lieux stratégiques où se joue l'indépendance des pays. L'auteur analyse d'abord les mécanismes et les acteurs des marchés libres, mettant en lumière les limites du jeu libéral de l'offre et de la demande. Son examen des divers systèmes de régulation qui ont été expérimentés l'amènent ensuite à émettre de sérieuses réserves sur l'efficacité des stocks régulateurs. De même, les accords compensatoires (type prêts du FMI) se heurtent-ils à des difficultés théoriques et concrètes de mise en place. La régulation de l'offre n'a véritablement réussi que dans le cas du pétrole. Des solutions plus radicales existent en dehors d'un fonctionnement aménagé du marché : ouverture unilatérale des frontières pour certains produits ; indexation des prix, maîtrise des circuits de transformation et commercialisation. Toutes solutions qui supposent une modification profonde des règles des échanges internationaux. [4e de couv.]\",\n",
       "       \"Ce que je crois L'appel qu'André Chouraqui fait entendre de Jérusalem se situe au coeur des vocations de cette cité, dont la voix retentit quand le monde est en péril de mort. Le témoignage est ici le fruit d'une vie qui se déploie à partir de trois pays et de trois cultures : l' Algérie, où il naît et dont il évoque les souvenirs, non sans nostalgie ni truculence ; la France, où sa pensée se forge à l'heure de Hitler, tandis qu'il prend part aux luttes de la Résistance ; Israël enfin, où se situent les sources de ses traditions ancestrales et son espoir d'une réalisation des idéaux de la Bible, dont il a publié récemment une traduction magistrale. Le regard que Chouraqui jette sur le monde moderne s'angoisse des germes de mort qu'il y décèle. Son livre explique de l'intérieur l'univers des Hébreux, les raisons de la survivance juive et de la renaissance d'Israël. Il nous donne des clés pour comprendre l'affrontement de l'hellénisme et de l'hébraïsme, les rivalités théologiques de l'Eglise et de la Synagogue, l'antisémitisme chrétien, les guerres judéo-arabes.\",\n",
       "       \"Homo hierarchicus : le système des castes et ses implications Après la dernière guerre, l'anthropologie sociale, caractérisée par 'l'observation participante' du chercheur 'sur le terrain', a commencé à s'appliquer, au-delà des petites sociétés de face-à-face, à de grands ensembles sociaux. Ainsi Louis Dumont s'est consacré pendant une vingtaine d'années à une découverte sociologique de l'Inde, qui aboutit au présent livre. Depuis lors, il met en œuvre le contraste entre la société des castes et la nôtre pour obtenir une vue comparative des idées et valeurs modernes. L'éditeur\",\n",
       "       'Économie de la santé : faits et chiffres La 4e de couv. indique : \"L\\'explosion du coût de la santé, depuis 1960 environ, résulte d\\'une détérioration du mode de vie, et d\\'une certaine stagnation du progrès thérapeutique. Le milieu, dont l\\'amélioration a été si bénéfique pour l\\'allongement de la longévité, devient de plus en plus pathogène et dangereux : aussi, les facteurs extérieurs de mode de vie et de comportement viennent-ils souvent annuler les progrès de la médecine. De leur côté, les systèmes de santé, plus préoccupés par leur fonction réparatrice, ne se trouvent pas dans les conditions d\\'un renouveau de la recherche clinique et enregistrent une certaine stagnation du progrès thérapeutique. Les projets qui ne visent pas à agir sur ces deux phénomènes et leur conjonction ne peuvent être qu\\'inopérants. En attendant un nouvel essor médical, la solution, si elle existe, se trouve en amont des systèmes de soins. La santé devient l\\'affaire de tous, elle relève de plus en plus du politique. Telle est la thèse centrale de cet ouvrage. Une thèse qui fera certainement l\\'objet de controverses, mais qui n\\'en a pas moins le mérite d\\'être etayée sur une analyse extrêmement fouillée et documentée. La réalité économique et sociale est complexe : chiffres, tableaux et graphiques, ont pour objet d\\'en donner une présentation simplifiée mais certainement pas au point de ramener ce livre à quelques idées trop simples (bienfaits de la société de consommation ou caractère pathogène de la société industrielle) qui seraient fausses : dans ce domaine où la causalité n\\'est pas linéaire et cartésienne, mais circulaire et dialectique, Etienne Barral, économiste, administrateur d\\'hôpital, enseignant d\\'économie sociale, apporte un ouvrage de référence aux multiples prolongements politiques.\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_descr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer_output \u001b[39m=\u001b[39m tokenizer(sample_descr, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m, max_length\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2561\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2559\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2560\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2561\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2562\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2619\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2619\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2620\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2621\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m     )\n\u001b[1;32m   2624\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2625\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2626\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2627\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2628\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "tokenizer_output = tokenizer(sample_descr, padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probas_from_logits(logits):\n",
    "    return logits.softmax(-1)\n",
    "\n",
    "\n",
    "def visualize_mlm_predictions(tokenizer_output, model_output, tokenizer, nb_candidates=10):\n",
    "    # Decode the tokenized sentences and clean-up the special tokens\n",
    "    decoded_tokenized_sents = [sent.replace('<pad>', '').replace('<mask>', ' <mask>') for sent in tokenizer.batch_decode(tokenizer_output.input_ids)]\n",
    "\n",
    "    # Retrieve the probas at the masked positions\n",
    "    masked_tokens_mask = tokenizer_output.input_ids == tokenizer.mask_token_id\n",
    "    batch_mask_probas = get_probas_from_logits(model_output.logits[masked_tokens_mask])\n",
    "\n",
    "    for sentence, mask_probas in zip(decoded_tokenized_sents, batch_mask_probas):\n",
    "        # Get top probas and plot them\n",
    "        top_probas, top_token_ids = mask_probas.topk(nb_candidates, -1)\n",
    "        top_tokens = tokenizer.convert_ids_to_tokens(top_token_ids)\n",
    "        bar_chart = px.bar({\"tokens\": top_tokens[::-1], \"probas\": list(top_probas)[::-1]},\n",
    "                        x=\"probas\", y=\"tokens\", orientation='h', title=sentence, width=800)\n",
    "        bar_chart.show(config={'staticPlot': True})\n",
    "\n",
    "visualize_mlm_predictions(tokenizer_output, model_output, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   5,  100, 1483,   73,   13,   48,  915,   15,   13, 2572,   42,  249,\n",
      "          329,   44,  619,    6,    1,    1,    1,    1]])\n",
      "torch.Size([1, 20]) torch.Size([1, 20])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "<s> Je regarderai la serie à la télévision avec mes enfants ce soir</s><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# Camembert tokenizer\n",
    "camembert_input = camembert_tokenizer(text_example, padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n",
    "print(camembert_input['input_ids'])\n",
    "print(camembert_input[\"input_ids\"].shape, bert_input[\"attention_mask\"].shape)\n",
    "print(camembert_input['attention_mask'])\n",
    "print(camembert_tokenizer.decode(camembert_input.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "torch.Size([1, 20]) torch.Size([1, 20])\n",
      "tensor([[  101, 13796, 42047, 12015, 10116, 10109, 11185,   254, 10109, 33110,\n",
      "         10460, 17954, 18374, 10794, 50520,   102,     0,     0,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "['[CLS]', 'Je', 'regard', '##era', '##i', 'la', 'serie', 'à', 'la', 'télévision', 'avec', 'mes', 'enfants', 'ce', 'soir', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# More complex tokenizerr\n",
    "encoding = tokenizer.encode_plus(\n",
    "    text_example,\n",
    "    add_special_tokens=True,\n",
    "    max_length=20,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding=\"max_length\",\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Check model\n",
    "print(encoding.keys())\n",
    "# Check shapes\n",
    "print(encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape)\n",
    "# Check contents of encoding outputs\n",
    "print(encoding[\"input_ids\"])\n",
    "print(encoding[\"attention_mask\"])\n",
    "# Inverse tokenization to get back words\n",
    "print(tokenizer.convert_ids_to_tokens(encoding.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tokens by description\n",
    "token_counts = []\n",
    "df_train_sample = df_train.sample(n=20000, random_state=42)\n",
    "for _, row in df_train_sample.iterrows():\n",
    "  token_count = len(tokenizer.encode(\n",
    "    row[\"descr\"],\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    "  ))\n",
    "  token_counts.append(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 512.0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histplot\n",
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 512])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the comments contain less than 300 tokens or more than 512. So, we’ll stick with the limit of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: tokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        descr = data_row.descr\n",
    "        labels = data_row[mlb.classes_]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            descr = descr,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['descr', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check on an item from the dataset\n",
    "train_dataset = RameauLabelDataset(\n",
    "  df_train_sample,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Les réseaux de symptômes en psychopathologie : enjeux théoriques, méthodologiques et sémiologiques Les débats contemporains sur les classifications psychiatriques illustrent la complexité des troubles psychiatriques. Ces tensions ne sont pas seulement cliniques mais relèvent de défis théoriques, méthodologiques et épistémologiques. L'un de ces débats concerne une tendance récente à s'éloigner des catégories diagnostiques conventionnelles pour se concentrer sur les symptômes individuels. L'accent est mis sur la forme et la structure des relations entre les éléments sémiologiques. Parmi les nombreux modèles promettant d'améliorer notre compréhension des troubles psychologiques, les réseaux de symptômes en psychopathologie proposent de concevoir le trouble psychiatrique comme une propriété émergente résultant d'interactions entre symptômes. Ces interactions s'alignent sur la manière dont les cliniciens perçoivent les symptômes de leur patient en tant que réseaux de problèmes qui s'influencent mutuellement. La multitude de classifications et de styles de pensée en psychopathologie nécessite le développement d'un cadre de travail intégratif et pluraliste. L'approche en réseaux de symptômes s'inscrit dans cette volonté d'intégration. Cette introduction aux réseaux de symptômes est destinée à un public de cliniciens et de chercheurs en psychologie et en psychiatrie non spécialistes mais intéressés par les approches émergentes, les nouvelles classifications, les apports de la science des réseaux et l'épistémologie pour leur pratique.\n",
      "Labels:  tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Shape:  torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Description: \", sample_item[\"descr\"])\n",
    "print(\"Labels: \", sample_item[\"labels\"])\n",
    "print(\"Shape: \", sample_item[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertModel.__init__() got an unexpected keyword argument 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load pretrained model and pass a sample of batch data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bert_model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(BERT_MODEL_NAME, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m sample_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)))\n\u001b[1;32m      5\u001b[0m sample_batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape, sample_batch[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_pretrained_bert/modeling.py:600\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: BertModel.__init__() got an unexpected keyword argument 'return_dict'"
     ]
    }
   ],
   "source": [
    "# Load pretrained model and pass a sample of batch data\n",
    "bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "\n",
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=8, num_workers=2)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape\n",
    "\n",
    "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "print(output.last_hidden_state.shape, output.pooler_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = bert_model(sample_item['input_ids'].unsqueeze(dim=0), sample_item[\"attention_mask\"].unsqueeze(dim=0))\n",
    "prediction.last_hidden_state.shape, prediction.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = RameauLabelDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = RameauLabelDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.val_dataset = RameauLabelDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = RameauLabelDataModule(\n",
    "    df_train, \n",
    "    df_test, \n",
    "    df_valid100, \n",
    "    camembert_tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_len = MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class RameauLabelTagger(pl.LightningModule):\n",
    "  \n",
    "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.bert = BertModcel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.BCELoss()\n",
    "    self.training_step_outputs = []\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    output = self.classifier(output.pooler_output)\n",
    "    output = torch.sigmoid(output)\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.training_step_outputs.append(loss)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": batch[\"labels\"]}\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  \n",
    "\n",
    "  def on_train_epoch_end(self, outputs):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for output in outputs:\n",
    "      for out_labels in output[\"labels\"].detach().cpu():\n",
    "        labels.append(out_labels)\n",
    "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "        predictions.append(out_predictions)\n",
    "\n",
    "    labels = torch.stack(labels).int()\n",
    "    predictions = torch.stack(predictions)\n",
    "\n",
    "    for i, name in enumerate(mlb.classes_):\n",
    "      class_roc_auc = torchmetrics.AUROC(predictions[:, i], labels[:, i])\n",
    "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "      \n",
    "    # epoch_average = torch.stack(self.training_step_outputs).mean()\n",
    "    # self.log(\"training_epoch_average\", epoch_average)\n",
    "    # self.training_step_outputs.clear()\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20876, 104380)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662804195/662804195 [01:19<00:00, 8349284.22B/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BertModel.__init__() got an unexpected keyword argument 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Instance of the current model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m RameauLabelTagger(\n\u001b[1;32m      3\u001b[0m   n_classes\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(mlb\u001b[39m.\u001b[39;49mclasses_),\n\u001b[1;32m      4\u001b[0m   n_warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[1;32m      5\u001b[0m   n_training_steps\u001b[39m=\u001b[39;49mtotal_training_steps\n\u001b[1;32m      6\u001b[0m )\n",
      "Cell \u001b[0;32mIn[182], line 6\u001b[0m, in \u001b[0;36mRameauLabelTagger.__init__\u001b[0;34m(self, n_classes, n_training_steps, n_warmup_steps)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_classes: \u001b[39mint\u001b[39m, n_training_steps\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_warmup_steps\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m   \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(BERT_MODEL_NAME, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      7\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size, n_classes)\n\u001b[1;32m      8\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_training_steps \u001b[39m=\u001b[39m n_training_steps\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_pretrained_bert/modeling.py:600\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: BertModel.__init__() got an unexpected keyword argument 'return_dict'"
     ]
    }
   ],
   "source": [
    "# Instance of the current model\n",
    "model = RameauLabelTagger(\n",
    "  n_classes=len(mlb.classes_),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5104, 0.4966, 0.4723,  ..., 0.4466, 0.5906, 0.3160],\n",
       "        [0.5355, 0.5175, 0.4515,  ..., 0.4375, 0.5990, 0.3143],\n",
       "        [0.5286, 0.5136, 0.4514,  ..., 0.4386, 0.5988, 0.3228],\n",
       "        ...,\n",
       "        [0.5371, 0.5350, 0.4555,  ..., 0.4332, 0.5988, 0.3072],\n",
       "        [0.5555, 0.5151, 0.4443,  ..., 0.4443, 0.5990, 0.3247],\n",
       "        [0.5502, 0.5014, 0.4363,  ..., 0.4384, 0.6002, 0.3204]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7168, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"./checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the progress in Tensorboard\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"Rameau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer = pl.Trainer(\n",
    "  logger=logger,\n",
    "  callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "  max_epochs=N_EPOCHS,\n",
    "  devices=1,\n",
    "  accelerator=\"gpu\",\n",
    "  enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"require_grad\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bert       | BertModel | 108 M \n",
      "1 | classifier | Linear    | 79.2 M\n",
      "2 | criterion  | BCELoss   | 0     \n",
      "-----------------------------------------\n",
      "187 M     Trainable params\n",
      "0         Non-trainable params\n",
      "187 M     Total params\n",
      "750.134   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aurelie/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/10439 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, data_module)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 531\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    532\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    533\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    561\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    564\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    566\u001b[0m     ckpt_path,\n\u001b[1;32m    567\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    568\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m )\n\u001b[0;32m--> 570\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    572\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    972\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1017\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1018\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1019\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:218\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[1;32m    219\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:185\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         closure()\n\u001b[1;32m    180\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    187\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:260\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    259\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    261\u001b[0m     trainer,\n\u001b[1;32m    262\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    263\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    264\u001b[0m     batch_idx,\n\u001b[1;32m    265\u001b[0m     optimizer,\n\u001b[1;32m    266\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    267\u001b[0m )\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:140\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    143\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1256\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1224\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:155\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:225\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 225\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:114\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/transformers/optimization.py:439\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    437\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    441\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    442\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m group[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:101\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     93\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     94\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     95\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_fn()\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward_fn(step_output\u001b[39m.\u001b[39;49mclosure_loss)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:232\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_fn\u001b[39m(loss: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     call\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer, \u001b[39m\"\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m\"\u001b[39;49m, loss, optimizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    290\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:200\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    198\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpre_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[0;32m--> 200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49mbackward(closure_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, optimizer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    202\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpost_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:67\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m     tensor: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     56\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     model\u001b[39m.\u001b[39;49mbackward(tensor, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1046\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fabric\u001b[39m.\u001b[39mbackward(loss, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1045\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1046\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "trained_model = RameauLabelTagger.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_classes=len(mlb.classes_)\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "MAX_TOKEN_COUNT = 512\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "val_dataset = RameauLabelDataset(\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "  _, prediction = trained_model(\n",
    "    item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "  )\n",
    "  predictions.append(prediction.flatten())\n",
    "  labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "THRESHOLD = 0.7\n",
    "accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC\n",
    "print(\"AUROC per tag\")\n",
    "for i, name in enumerate(mlb.classes_):\n",
    "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
    "  print(f\"{name}: {tag_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "upper, lower = 1, 0\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true,\n",
    "  y_pred,\n",
    "  target_names=mlb.classes_,\n",
    "  zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abes_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "79d7ff32004ac4c5bc1812f118fca289ef6cc0cea24529fb05e42e57e2fccd5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
