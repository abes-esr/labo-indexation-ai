{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel text classification using BERT family\n",
    "\n",
    "from: \n",
    "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=Lk6Cq9duKBkA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from \n",
    "https://colab.research.google.com/drive/1ejBYmu0P5urzghoTTDB-GBUxpbUFX0Gz?usp=sharing#scrollTo=p5Iuv7q7Dtg_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# remove any unwanted garbage using the collector\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn \n",
    "import tqdm.notebook as tq\n",
    "import warnings\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import training_args, Trainer\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/aurelie/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Wed Jul 12 08:13:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  Off |\n",
      "| 30%   45C    P8    22W / 450W |  17649MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    259738      C   .../abes_index_dl/bin/python    16198MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"/data\"\n",
    "output_path = path + \"/outputs\"\n",
    "fig_path = path + \"/figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f024c211b90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "os.environ[\"require_grad\"] = \"False\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  (125220, 103022)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m\"\u001b[39m\u001b[39mtrain_dataset_for_DL.pkl\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain dataset: \u001b[39m\u001b[39m\"\u001b[39m, df_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_path, \u001b[39m\"\u001b[39;49m\u001b[39mtest_dataset_for_DL.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest dataset: \u001b[39m\u001b[39m\"\u001b[39m, df_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m df_valid100 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m\"\u001b[39m\u001b[39mvalid100_dataset_for_DL.pkl\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/io/pickle.py:196\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m         \u001b[39m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mWarning\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m    197\u001b[0m \u001b[39mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    198\u001b[0m     \u001b[39m# e.g.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m pc\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/_libs/internals.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.internals._unpickle_block\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2385\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[1;32m   2381\u001b[0m     values \u001b[39m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   2382\u001b[0m     \u001b[39mreturn\u001b[39;00m klass(values, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, placement\u001b[39m=\u001b[39mplacement, refs\u001b[39m=\u001b[39mrefs)\n\u001b[0;32m-> 2385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_block\u001b[39m(\n\u001b[1;32m   2386\u001b[0m     values, placement, \u001b[39m*\u001b[39m, ndim: \u001b[39mint\u001b[39m, refs: BlockValuesRefs \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2387\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Block:\n\u001b[1;32m   2388\u001b[0m     \u001b[39m# caller is responsible for ensuring values is NOT a PandasArray\u001b[39;00m\n\u001b[1;32m   2390\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(placement, BlockPlacement):\n\u001b[1;32m   2391\u001b[0m         placement \u001b[39m=\u001b[39m BlockPlacement(placement)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## load data (takes around 1min30s)\n",
    "df_train = pd.read_pickle(os.path.join(data_path, \"train_dataset_for_DL.pkl\"))\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "df_test = pd.read_pickle(os.path.join(data_path, \"test_dataset_for_DL.pkl\"))\n",
    "print(\"Test dataset: \", df_test.shape)\n",
    "df_valid100 = pd.read_pickle(os.path.join(data_path, \"valid100_dataset_for_DL.pkl\"))\n",
    "print(\"Validation dataset: \", df_valid100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125220 entries, 0 to 125219\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "train dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29227 entries, 0 to 29226\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "ntest dataset memory usage:  None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Columns: 103022 entries, !Xóõ (langue) to descr\n",
      "dtypes: Sparse[int64, 0](103021), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "validation dataset memory usage:  None\n"
     ]
    }
   ],
   "source": [
    "# Check memory space\n",
    "print(\"train dataset memory usage: \", df_train.info())\n",
    "print()\n",
    "print(\"ntest dataset memory usage: \", df_test.info())\n",
    "print()\n",
    "print(\"validation dataset memory usage: \", df_valid100.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['!Xóõ (langue)', '\"Sprach- und Sachatlas Italiens und der Südschweiz\"',\n",
      "       '\"Taalatlas van Noord- en Zuid-Nederland\"', ''?d', ''?ntokyo',\n",
      "       ''Are'are (peuple des îles Salomon)', ''Au keto',\n",
      "       ''Au keto, Musique d'', ''Au ni aau', ''Au ni aau, Musique d'',\n",
      "       ...\n",
      "       'évangéliaire de split', 'Ālāp', 'Ārbajo, Musique d'',\n",
      "       'Đinh pơng, Musique de', 'Ō-tsuzumi, Musique d'', 'ʿArūbi', 'Ḥawfi',\n",
      "       'Ṭhumrī', 'Ṭār (tambour), Musique de', 'descr'],\n",
      "      dtype='object', length=103022)\n"
     ]
    }
   ],
   "source": [
    "## Show columns\n",
    "print(\"Features: \", df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  La bataille mondiale des matières premières Dans le débat sur un nouvel ordre économique international, les marchés mondiaux des matières premières constituent un enjeu de première importance. Ils conditionnent largement les moyens de financement du développement de pays pauvres et sont un des lieux stratégiques où se joue l'indépendance des pays. L'auteur analyse d'abord les mécanismes et les acteurs des marchés libres, mettant en lumière les limites du jeu libéral de l'offre et de la demande. Son examen des divers systèmes de régulation qui ont été expérimentés l'amènent ensuite à émettre de sérieuses réserves sur l'efficacité des stocks régulateurs. De même, les accords compensatoires (type prêts du FMI) se heurtent-ils à des difficultés théoriques et concrètes de mise en place. La régulation de l'offre n'a véritablement réussi que dans le cas du pétrole. Des solutions plus radicales existent en dehors d'un fonctionnement aménagé du marché : ouverture unilatérale des frontières pour certains produits ; indexation des prix, maîtrise des circuits de transformation et commercialisation. Toutes solutions qui supposent une modification profonde des règles des échanges internationaux. [4e de couv.]\n",
      "Concepts:  {'Matières premières': 1, 'Relations économiques internationales': 1}\n"
     ]
    }
   ],
   "source": [
    "# get one row\n",
    "row_id = 64\n",
    "label_cols = df_train.columns[:-1]\n",
    "sample_row = df_train.iloc[row_id]\n",
    "sample_descr = sample_row.descr\n",
    "sample_labels = sample_row[label_cols]\n",
    "\n",
    "print(\"Description: \", sample_descr)\n",
    "print(\"Concepts: \", sample_labels[sample_labels != 0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sample datasets\\ndf_train = df_train.sample(n=10000, random_state=42)\\nprint(\"Train dataset: \", df_train.shape)\\n#df_test = df_test.sample(n=3000, random_state=42)\\nprint(\"Test dataset: \", df_test.shape)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample datasets\n",
    "df_train = df_train.sample(n=80000, random_state=42)\n",
    "print(\"Train dataset: \", df_train.shape)\n",
    "df_test = df_test.sample(n=20000, random_state=42)\n",
    "print(\"Test dataset: \", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Remove useless columns (labels not used in train dataset - Takes > 5min)\\ncols_to_remove = df_train.columns[df_train.sum() == 0]\\nlen(cols_to_remove)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Remove useless columns (labels not used in train dataset - Takes > 5min)\n",
    "cols_to_remove = df_train.columns[df_train.sum() == 0]\n",
    "len(cols_to_remove)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Remove useless columns\\ndf_train = df_train.drop(columns=cols_to_remove)\\nprint(\"Train dataset:\", df_train.shape)\\ndf_test = df_test.drop(columns=cols_to_remove)\\nprint(\"Test dataset:\", df_test.shape)\\ndf_valid100 = df_valid100.drop(columns=cols_to_remove)\\nprint(\"Validation dataset:\", df_valid100.shape)\\nlabel_cols = df_train.columns[:-1]\\nprint(\"Nombre de labels:\", len(label_cols))\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Remove useless columns\n",
    "df_train = df_train.drop(columns=cols_to_remove)\n",
    "print(\"Train dataset:\", df_train.shape)\n",
    "df_test = df_test.drop(columns=cols_to_remove)\n",
    "print(\"Test dataset:\", df_test.shape)\n",
    "df_valid100 = df_valid100.drop(columns=cols_to_remove)\n",
    "print(\"Validation dataset:\", df_valid100.shape)\n",
    "label_cols = df_train.columns[:-1]\n",
    "print(\"Nombre de labels:\", len(label_cols))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93915, 103022) (31305, 103022)\n"
     ]
    }
   ],
   "source": [
    "# Separate train dataset into train and validation sets for model \n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_val = train_test_split(df_train, test_size = 0.25)\n",
    "print(data_train.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103021\n"
     ]
    }
   ],
   "source": [
    "LABEL_COLUMNS = data_train.columns[:-1]\n",
    "id2label = {idx:label for idx, label in enumerate(LABEL_COLUMNS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABEL_COLUMNS)}\n",
    "print(len(LABEL_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Histoire                            4539\n",
       "Aspect social                       1599\n",
       "Manuels d'enseignement supérieur    1213\n",
       "Français (langue)                   1194\n",
       "Philosophie                         1133\n",
       "Mathématiques                       1053\n",
       "Étude et enseignement (primaire)    1047\n",
       "Étude et enseignement                994\n",
       "Droit                                936\n",
       "Bandes dessinées                     928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[LABEL_COLUMNS].sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sample test_set\\ndata_test = df_test.sample(n=5000)\\nprint(\"data_test shape:\", data_test.shape)\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample test_set\n",
    "data_test = df_test.sample(n=10000)\n",
    "print(\"data_test shape:\", data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(label_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enfants perdus de Roumanie : histoire des orphelinats de Ceausescu Images d'enfants maltraités, mal nourris, privés d'accès aux soins, entassés dans des bâtisses insalubres : en 1989, l'opinion internationale découvrait avec effroi l'enfer des « orphelinats de Ceausescu », au point que leur démantèlement fut une condition sine qua non de l'adhésion de la Roumanie à l'Union européenne. Au-delà des représentations sensationnalistes diffusées par la presse et les organisations internationales, la réalité de ce phénomène reste encore largement méconnue. Une certitude : du fait d'un manque cruel de moyens et de personnel qualifié, ces « enfants de l'État » ont, par dizaines de milliers, subi pendant des années, sans possibilité d'échappatoire, la rudesse des conditions de vie sous le régime socialiste et une violence quotidienne au sein des institutions censées les prendre en charge. En s'appuyant sur des sources nationales et locales inexplorées, sur de nombreux témoignages d'anciens mineurs placés, mais aussi sur ses douze années d'observation et de travail social sur le terrain, Jean-Philippe Légaut nous montre pourquoi et comment ces structures ont condamné ceux qu'elles auraient dû protéger.\n",
      "{'Enfants abandonnés': 1, 'Orphelinats': 1, 'Politique publique': 1}\n"
     ]
    }
   ],
   "source": [
    "# Select one example\n",
    "id = 56\n",
    "sample_row = data_train.iloc[id]\n",
    "sample_text = sample_row.descr\n",
    "sample_labels = sample_row[LABEL_COLUMNS][sample_row[LABEL_COLUMNS] == 1 ]\n",
    "print(sample_text)\n",
    "print(sample_labels.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "model_name = 'camembert-base'\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item_idx: int):\n",
    "        data_row = self.data.iloc[item_idx]\n",
    "        descr = data_row.descr\n",
    "        descr = \" \".join(descr.split())\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "\n",
    "        # Tokenization\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        #attention_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            #'description': descr,\n",
    "            'input_ids': input_ids ,\n",
    "            #'attention_mask': attention_mask,\n",
    "            'labels':torch.FloatTensor(labels)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "training_set = RameauLabelDataset(data_train, tokenizer, MAX_LEN)\n",
    "validation_set = RameauLabelDataset(data_val, tokenizer, MAX_LEN)\n",
    "testing_set = RameauLabelDataset(df_test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'pin_memory': True,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "               'pin_memory': True, \n",
    "               'shuffle': False,\n",
    "               'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **test_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoModelForSequenceClassification\\n\\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\\nmodel.to(device)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\n",
    "model.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): CamembertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=103021, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = CamembertModel.from_pretrained(model_name, return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, len(label_cols))\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        output = self.bert_model(input_ids)\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loo^p\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs = data['input_ids'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    model\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m avg_loss \u001b[39m=\u001b[39m train_one_epoch(epoch_number, writer)\n\u001b[1;32m     18\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# statistics for batch normalization.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 9\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index, tb_writer)\u001b[0m\n\u001b[1;32m      4\u001b[0m last_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Here, we use enumerate(training_loader) instead of\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# iter(training_loader) so that we can track the batch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# index and do some intra-epoch reporting\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(training_loader):\n\u001b[1;32m     10\u001b[0m     \u001b[39m# Every data instance is an input + label pair\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     inputs \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     labels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m, in \u001b[0;36mRameauLabelDataset.__getitem__\u001b[0;34m(self, item_idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item_idx: \u001b[39mint\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     data_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49miloc[item_idx]\n\u001b[1;32m     13\u001b[0m     descr \u001b[39m=\u001b[39m data_row\u001b[39m.\u001b[39mdescr\n\u001b[1;32m     14\u001b[0m     descr \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(descr\u001b[39m.\u001b[39msplit())\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/indexing.py:1658\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1658\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_ixs(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/frame.py:3652\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3650\u001b[0m \u001b[39m# irow\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 3652\u001b[0m     new_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mfast_xs(i)\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(new_mgr\u001b[39m.\u001b[39marray, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m new_mgr\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39mbase \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/internals/managers.py:1052\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     block \u001b[39m=\u001b[39m new_block(\n\u001b[1;32m   1045\u001b[0m         result,\n\u001b[1;32m   1046\u001b[0m         placement\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(result)),\n\u001b[1;32m   1047\u001b[0m         ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1048\u001b[0m         refs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrefs,\n\u001b[1;32m   1049\u001b[0m     )\n\u001b[1;32m   1050\u001b[0m     \u001b[39mreturn\u001b[39;00m SingleBlockManager(block, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 1052\u001b[0m dtype \u001b[39m=\u001b[39m interleaved_dtype([blk\u001b[39m.\u001b[39;49mdtype \u001b[39mfor\u001b[39;49;00m blk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks])\n\u001b[1;32m   1054\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[39m# GH#46406\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/internals/base.py:224\u001b[0m, in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(dtypes):\n\u001b[1;32m    222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m find_common_type(dtypes)\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1457\u001b[0m, in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[39mreturn\u001b[39;00m first\n\u001b[1;32m   1456\u001b[0m \u001b[39m# get unique types (dict.fromkeys is used as order-preserving set())\u001b[39;00m\n\u001b[0;32m-> 1457\u001b[0m types \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mdict\u001b[39;49m\u001b[39m.\u001b[39;49mfromkeys(types)\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(t, ExtensionDtype) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m types):\n\u001b[1;32m   1460\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m types:\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/arrays/sparse/dtype.py:137\u001b[0m, in \u001b[0;36mSparseDtype.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Ignore spurious numpy warning\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[1;32m    132\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39melementwise comparison failed\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m                 category\u001b[39m=\u001b[39m\u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m             )\n\u001b[0;32m--> 137\u001b[0m             fill_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_value \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mfill_value\n\u001b[1;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m subtype \u001b[39mand\u001b[39;00m fill_value\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/abes_index_dl/lib/python3.11/site-packages/pandas/core/arrays/sparse/dtype.py:142\u001b[0m, in \u001b[0;36mSparseDtype.fill_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[39mreturn\u001b[39;00m subtype \u001b[39mand\u001b[39;00m fill_value\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfill_value\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    The fill value of the array.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m       ``SparseArray.fill_value`` directly.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mmodel_weights.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('camembert_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model on gpu\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create defait learning rate scheduler from Trainer\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 10\n",
    "batch_per_epoch = 30\n",
    "num_training_steps = num_epochs * batch_per_epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for i, batch in enumerate(training_loader,0):\n",
    "    while i < batch_per_epoch:\n",
    "        for epoch in range(num_epochs):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1_score\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "  \n",
    "    ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "    outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(outputs, targets)\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for data in training_loader:\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch)\n",
    "        \n",
    "\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training time: {stop - start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['labels'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "      predictions - \n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    \n",
    "    descr = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    target_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for data in data_loader:\n",
    "        #descr = data[\"descr\"]\n",
    "        ids = data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "        targets = data[\"labels\"].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
    "        outputs = torch.sigmoid(outputs).detach().cpu()\n",
    "        # thresholding at 0.5\n",
    "        preds = outputs.round()\n",
    "        targets = targets.detach().cpu()\n",
    "\n",
    "        descr.extend(descr)\n",
    "        predictions.extend(preds)\n",
    "        prediction_probs.extend(outputs)\n",
    "        target_values.extend(targets)\n",
    "    \n",
    "    predictions = torch.stack(predictions)\n",
    "    prediction_probs = torch.stack(prediction_probs)\n",
    "    target_values = torch.stack(target_values)\n",
    "    \n",
    "    return predictions, prediction_probs, target_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_metrics import *\n",
    "THRESHOLD = 0.05\n",
    "for epoch in range(EPOCHS):\n",
    "    outputs_prob, targets = validation(epoch)\n",
    "    outputs = np.array(outputs_prob) >= THRESHOLD\n",
    "    results = label_metrics_report(\n",
    "        modelName = model_name,\n",
    "        y_true = targets,\n",
    "        y_pred = outputs,\n",
    "        y_prob=None,\n",
    "        print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = outputs[0]\n",
    "t[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY CAMEMBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RameauLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item_idx: int):\n",
    "        data_row = self.data.iloc[item_idx]\n",
    "        descr = data_row.descr\n",
    "        descr = \" \".join(descr.split())\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "\n",
    "        # Tokenization\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            descr,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            #'description': descr,\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'labels':torch.FloatTensor(labels)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "train_dataset = RameauLabelDataset(data_train, tokenizer)\n",
    "sample_item = train_dataset[0]\n",
    "print(\"keys:\", sample_item.keys())\n",
    "#print(\"description:\", sample_item[\"description\"])\n",
    "print(\"labels:\", sample_item[\"labels\"])\n",
    "print(sample_item[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-05\n",
    "THRESHOLD = 0.08 # threshold for the sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Module\n",
    "class RameauLabelDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, val_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = RameauLabelDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "            \n",
    "        self.val_dataset = RameauLabelDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        self.test_dataset = RameauLabelDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the data_module\n",
    "data_module = RameauLabelDataModule(\n",
    "    data_train, \n",
    "    data_val, \n",
    "    df_test, \n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_len = MAX_LEN)\n",
    "\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class RameauLabelClassifier(pl.LightningModule):\n",
    "  # Set up the classifier\n",
    "  def __init__(self, config: dict):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.pretrained_model = CamembertModel.from_pretrained(config['model_name'], return_dict = True)\n",
    "    self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "    self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
    "    self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    self.dropout = nn.Dropout()  \n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    # roberta layer\n",
    "    output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "    # final logits\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "    pooled_output = self.hidden(pooled_output)\n",
    "    pooled_output = F.relu(pooled_output)\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "    logits = self.classifier(pooled_output)\n",
    "    # calculate loss\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "      loss = self.loss_func(logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
    "\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    self.log(\"train loss \", loss, prog_bar = True, logger=True)\n",
    "    return {\"loss\":loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "  def validation_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    self.log(\"validation loss \", loss, prog_bar = True, logger=True)\n",
    "    return {\"val_loss\": loss, \"predictions\":outputs, \"labels\": batch[\"labels\"]}\n",
    "\n",
    "  def predict_step(self, batch, batch_index):\n",
    "    loss, outputs = self(**batch)\n",
    "    return outputs\n",
    "  \n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])\n",
    "    total_steps = self.config['train_size']/self.config['batch_size']\n",
    "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "    warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    return [optimizer],[scheduler]\n",
    "\n",
    "  # def on_validation_epoch_end(self, outputs):\n",
    "  #   losses = []\n",
    "  #   for output in outputs:\n",
    "  #     loss = output['val_loss'].detach().cpu()\n",
    "  #     losses.append(loss)\n",
    "  #   avg_loss = torch.mean(torch.stack(losses))\n",
    "  #   self.log(\"avg_val_loss\", avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': model_name,\n",
    "    'n_labels': n_labels,\n",
    "    'batch_size': 128,\n",
    "    'max_len': 256,\n",
    "    'lr': 1.5e-6,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(data_module.train_dataloader()),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 100\n",
    "}\n",
    "\n",
    "model = RameauLabelClassifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "sample_item = train_dataset[idx]\n",
    "input_ids = sample_item[\"input_ids\"]\n",
    "attention_mask = sample_item['attention_mask']\n",
    "labels = sample_item['labels']\n",
    "model.cpu()\n",
    "loss, output = model(input_ids.unsqueeze(dim=0), attention_mask.unsqueeze(dim=0), labels.unsqueeze(dim=0))\n",
    "print(labels.shape, output.shape, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule\n",
    "data_module = data_module = RameauLabelDataModule(\n",
    "    data_train, \n",
    "    data_val, \n",
    "    df_test, \n",
    "    tokenizer,\n",
    "    batch_size=config['batch_size'],\n",
    "    max_token_len = config[\"max_len\"])\n",
    "\n",
    "data_module.setup() \n",
    "\n",
    "# model\n",
    "model = RameauLabelClassifier(config)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trainer and fit\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\", num_sanity_val_steps=50)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to convert list of comments into predictions for each comment\n",
    "def classify_raw_comments(model, dm):\n",
    "  predictions = trainer.predict(model, datamodule=dm)\n",
    "  flattened_predictions = np.stack([torch.sigmoid(torch.Tensor(p)) for batch in predictions for p in batch])\n",
    "  return flattened_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classify_raw_comments(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(df_train) // BATCH_SIZE\n",
    "print(\"steps per epoch:\", steps_per_epoch)\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "print(\"Total training steps:\", total_training_steps)\n",
    "warmup_steps = total_training_steps // 5\n",
    "print(\"Warmup steps: \", warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = RameauLabelClassifier(\n",
    "  n_classes=len(LABEL_COLUMNS),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=N_EPOCHS, accelerator=\"auto\", enable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the current model\n",
    "model = RameauLabelClassifier(\n",
    "  n_classes=len(label_cols),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves a file like: input/QTag-epoch=02-val_loss=0.32.ckpt\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    monitor='val_loss',# monitored quantity\n",
    "    filename='Rameau_BertMultilingualClassifier-{epoch:02d}-{val_loss:.2f}',\n",
    "    verbose=True,\n",
    "    save_top_k=3, #  save the top 3 models\n",
    "    mode='min', # mode of the monitored quantity  for optimization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the progress in Tensorboard\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"Bert_multilingual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = pl.Trainer(\n",
    "  logger=logger,\n",
    "  callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "  max_epochs=EPOCHS,\n",
    "  accelerator=\"gpu\",\n",
    "  enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "N_EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 300\n",
    "LR = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs =EPOCHS ,  accelerator=\"gpu\", callbacks=[checkpoint_callback], enable_progress_bar=True)\n",
    "# Train the Classifier Model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"./checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"test_loss\",\n",
    "  mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "trained_model = RameauLabelTagger.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_classes=len(label_cols)\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "MAX_TOKEN_COUNT = 512\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "val_dataset = RameauLabelDataset(\n",
    "  df_valid100,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "  _, prediction = trained_model(\n",
    "    item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "  )\n",
    "  predictions.append(prediction.flatten())\n",
    "  labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "THRESHOLD = 0.7\n",
    "torchmetrics.Accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC\n",
    "print(\"AUROC per tag\")\n",
    "for i, name in enumerate(label_cols):\n",
    "  tag_auroc = torchmetrics.AUROC(predictions[:, i], labels[:, i], pos_label=1)\n",
    "  print(f\"{name}: {tag_auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "upper, lower = 1, 0\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true,\n",
    "  y_pred,\n",
    "  target_names=label_cols,\n",
    "  zero_division=0\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abes_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "79d7ff32004ac4c5bc1812f118fca289ef6cc0cea24529fb05e42e57e2fccd5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
